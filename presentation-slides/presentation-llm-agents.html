<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to LLM-Based Agents</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

        class: center, middle

        # Getting Started with LLM Agents using LangChain
        ### By Lucas Soares

        ---

        # What is an Agent?

        --
        
        ## Thought + Action
        
        --

        - Example: [ReACT](https://arxiv.org/pdf/2210.03629.pdf) style Decision-making process for attending a live-training

        --

        - __Thought__: "I want to learn about agents"
        
        --
        
        - __Action__: "Go to the internet and research cool platforms where I can learn about agents"
        
        --
        
        - __Thought__: "O'Reilly has some awesome courses and live-trainings"
        
        --
        
        - __Action__: "Look up O'Reilly courses"
        
        --
        
        - __Thought__: "Live-trainings by instructor Lucas are awesome"
        
        --
        
        - __Action__: "Schedule live-training about agents with instructor Lucas Soares"

        ---

        ## Examples of Agent Implementations
        --

        - [BabyAGI](https://github.com/yoheinakajima/babyagi)

        --

        - [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
        
        --
        
        - [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)

        ---

        ## Andrej Karpathy on Agents

        <iframe width="560" height="315" src="https://www.youtube.com/embed/fqVLjtvWgq8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

        ---
        class: center, middle
        # Agents in 3 Levels of Complexity

        ---

        # Level 1: LLM + functions inside the prompt 

        --
        
        - ['Toolformer'](https://arxiv.org/pdf/2302.04761.pdf)

        --

        - LLMs can teach themselves how to properly call external tools!

        <img style="width: 400px "src="../notebooks/assets-resources/toolformer.png"> </img>

        ---

        # Level 1: LLM + functions inside the prompt

        --

        ```python
        from openai import OpenAI
        client = OpenAI()
        
        def get_response(prompt_question, model="gpt-3.5-turbo-16k"):
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": "You are a helpful research and programming assistant"},
                        {"role": "user", "content": prompt_question}]
            )
            
            return response.choices[0].message.content

        def create_directory(directory_name):
            subprocess.run(["mkdir", directory_name])

        def create_file(file_name):
            subprocess.run(["touch", file_name])

        def list_files():
            subprocess.run(["ls"])
        ```

        ---

        # Level 1: LLM + functions inside the prompt

        ```python

          task_description = "Create a folder called 'lucas-the-agent-master'. Inside that folder, create a file called 'the-10-master-rules.md"
          output = get_response(f"""Given this task: {task_description}, \n
                                  Consider you have access to the following functions:
                                  
          def create_directory(directory_name):
              '''Function that creates a directory given a directory name.'''
              subprocess.run(["mkdir", directory_name])
          
          def create_file(file_name):
              '''Function that creates a file given a file name.'''
              subprocess.run(["touch", file_name])
          
          def list_files():
            '''Function that lists all files in the current directory.'''
              subprocess.run(["ls"])
          
          Your output should be the first function to be executed to complete the task containing the necessary arguments.
          The OUTPUT SHOULD ONLY BE THE PYTHON FUNCTION CALL and NOTHING ELSE.
          """)
          
          Markdown(output)

          # Output:
          # create_directory('lucas-the-agent-master')
        ```

        ---

        # Level 1: LLM + functions inside the prompt

        - Look at that the output is that function! 
        Now, all we need is find a way to execute this function. 
        We can use Python's built in `exec` method for that:
        
        --
        ```python
        exec("model." + output)
        !ls -d */ | grep lucas
        # Output:
        # lucas-the-agent-master/
        ```
        
        ---

        # Limitations

        --

        - __Probabilistic outputs__ make function calls unreliable
        
        --

        - Need for __structured ways to prepare the inputs__ of 
        the function calls
        
        --
        
        - Putting entire functions inside text prompts is clunky and
        __non-scalable__
        
        --

        - Solution? __OpenAI Functions__!
        
        ---
        class: center, middle

        # OpenAI's Function Calling API
        
        ---

        # OpenAI Function Calling

        --

        - [OpenAI function calling](https://platform.openai.com/docs/guides/function-calling):

        ---

        # OpenAI Function Calling


        - [OpenAI function calling](https://platform.openai.com/docs/guides/function-calling): standard way to connect models to outside tools.

        --

        ### Steps

        --

        1. Call the model with the user query and a set of functions defined in the functions parameter.
        
        --
        
        2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema.
        
        --
        
        3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.
        
        --
        
        4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.
        

        ---

        # Step 1 & 2

        --
        
        ```python
        import json
        
        def create_directory(directory_name):
            # Function to create a directory
            subprocess.run(["mkdir", directory_name])
            return json.dumps({"directory_name": directory_name})
        
        tool_create_directory = {
            "type": "function",
            "function": {
                "name": "create_directory",
                "description": "Create a directory given a directory name.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "directory_name": {
                            "type": "string",
                            "description": "The name of the directory to create.",
                        }
                    },
                    "required": ["directory_name"],
                },
            },
        }
        tools = [tool_create_directory]

        ```

        ---

        # Step 1 & 2

        ```python

        def run_terminal_task():
            messages = [{"role": "user", "content": 
            "Create a folder called 'lucas-the-agent-master'."}]
            tools = [tool_create_directory]  
            response = client.chat.completions.create(
                model="gpt-3.5-turbo-16k",
                messages=messages,
                tools=tools,
                tool_choice="auto",
            )
            response_message = response.choices[0].message
            tool_calls = response_message.tool_calls
            # Check if the model called a function
            if tool_calls:
                # Proceed to step 3
        ```
        ---
        # Step 3: Parse and execute the function

        ```python
          available_functions = {
            "create_directory": create_directory,
        }
        messages.append(response_message)
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            function_response = function_to_call(
                directory_name=function_args.get("directory_name"),
            )
            messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )
        ```

        ---
        # Step 4: Summarize Results Back to User

        ```python
            second_response = client.chat.completions.create(
              model="gpt-3.5-turbo-16k",
              messages=messages,
          )
          return second_response

          output = run_terminal_task()

        ```

        ---
        class: center, middle

        ## Ready to Implement Your Own Functions?

        <span style="background-color: lightgreen">
          OpenAI Functions Demo
        </span>

        ---

        class: center, middle

        # Utilizing OpenAI's Function Calling API
        ### Implementing External Function Calls with Python and OpenAI

        ---

        # Introduction to OpenAI Functions

        ## Understanding OpenAI's Approach
        - Overview of OpenAI's function calling API
        - Link: [OpenAI Documentation](https://platform.openai.com/docs/guides/function-calling)


        ---

        # Agents and LangChain
        - Discussion on basics of agents
        - Implementation in Python
        - Use of frameworks like openai, langchain
        - Building productive agents

        ---

        ### Slide 2: LangChain Framework
        
        # LangChain Framework
        - Installation: `pip install openai langchain docarray ipydrawio ipydrawio_widgets`
        - [LangChain Introduction](https://python.langchain.com/docs/get_started/introduction)
        - Focus: Dynamic, reusable prompts for LLMs
        

        ---

        ### Slide 3: Main Features of LangChain
        
        # Main Features
        - **Components**: Abstractions for working with LMs
        - **Off-the-shelf chains**: Assembling components for tasks
        - Creation of complex pipelines
        

        ---

        ### Slide 4: Core Elements of LangChain

        # Core Elements
        - Models
        - Prompts
        - Output parsers
        

        ---

        ### Slide 5: Models in LangChain
        
        # Models
        - Abstractions over LLM APIs
        - Example with ChatGPT API
        - Usage of `ChatOpenAI` for model predictions

        ---

        ### Slide 6: Basic Components
        
        # Basic Components
        - Models
        - Prompt templates
        - Output parsers
        - Example of creating and using a prompt template

        ---

        ### Slide 7: Prompts and Output Parsers
        
        # Prompts and Output Parsers
        - Creating and formatting prompt templates
        - Example of an OutputParser converting lists

        ---

        ### Slide 8: Building with LangChain
        
        # Building with LangChain
        - Using "chains" for connecting components
        - Example of a chain with a prompt and LLM

        ---

        ### Slide 9: LangChain Expression Language (LCEL)
        
        # LCEL
        - New representation language in LangChain
        - Declarative composition of chains
        - Example using LCEL format

        ---

        ### Slide 10: LangChain Lab Exercises
        
        # Lab Exercises
        - Building a reporting agent
        - Components: Tool, Base LLM, Output conditions

        ---

        ### Slide 11: Creating an Agent
        
        # Creating an Agent
        - Defining tools and prompt templates
        - Binding tools to a ChatOpenAI model
        - Parsing output and invoking agent

        ---

        ### Slide 12: Agent Execution and Memory
        
        # Agent Execution and Memory
        - Implementing `AgentExecutor`
        - Incorporating chat history in agent interaction

        ---

        ### Conclusion
        - Recap of LangChain capabilities
        - Encouragement for experimentation and building with LangChain

        ---

        # LangChain Framework

        ## Introduction to LangChain
        - [LangChain](https://python.langchain.com/docs/get_started/introduction): Framework for LLM-powered applications
        - Composing prompts, models, tools for complex applications

        ---

        # Next Steps

        ## Building Agents with LangChain
        - Exploring LangChain in upcoming notebook
        - Deep dive into agent building

        ---

        # References

        - [HuggingGPT](https://github.com/microsoft/JARVIS)
        - [Gen Agents](https://arxiv.org/pdf/2304.03442.pdf)
        - [WebGPT](https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-answering-with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22)
        - [LangChain](https://python.langchain.com/docs/get_started/introduction)
        - [OpenAI](https://openai.com/)
        - [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
        - [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
        - [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)
        - [BabyAGI](https://github.com/yoheinakajima/babyagi)
        - [Karpathy on Agents](https://www.youtube.com/watch?v=fqVLjtvWgq8)
        - [ReACT Paper](https://arxiv.org/abs/2210.03629)

        ---

        class: center, middle

        # Conclusion
        ## Ready to Build Your Own Agents?        

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>


