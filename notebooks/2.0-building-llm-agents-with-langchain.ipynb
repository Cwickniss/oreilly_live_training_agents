{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"langchain[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is awesome, we can now use openai functions connected to the ChatGPT API endpoint to allow it to perform actions in the real world, and the calling of said functions is made easier by leveraging the json schema which structures how the model would call the function. \n",
    "\n",
    "This is a great setup and tool but more complex tasks, we want to have more control over the process these potential agents will go through in order to make them as reliable as possible. We want to control things like:\n",
    "\n",
    "- What goes in and out of prompts\n",
    "- What goes in and out of each thought and action pair stage the agent goes through when doing something in the real-world\n",
    "- A convenient interface to compose agents with useful building blocks (also leverage open source LLMs if we want to)\n",
    "\n",
    "I could go on but this is enough for now.\n",
    "\n",
    "For scenarios like these where just connecting a model to some tools won't cut it, a really great framework that has had a lot of sucess recently is [LangChain](https://python.langchain.com/docs/get_started/introduction).\n",
    "\n",
    "LangChain is a framework that allows for building LLM-powered applications by giging developers the ability to build and compose building blocks like prompts, models, tools and so on to develop complex and interesting applications.\n",
    "\n",
    "Here are the steps for building agents with Langchain:\n",
    "\n",
    "1. Setup the LLM\n",
    "2. Define the tool or list of tools\n",
    "3. Set up a prompt template\n",
    "4. Bind the llm with the tools\n",
    "5. Define the agent as a dictionary with keys: input, and agent scratchpad\n",
    "6. Use LCEL to connect agent, prompt and the LLM binded with tools\n",
    "7. Create the agent loop\n",
    "8. Wrap everything under `AgentExecutor`\n",
    "9. Invoke the agent with some query input\n",
    "\n",
    "Let's take a look below at a LangChain implementation of our simple agent that can create directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `create_directory` with `{'directory_name': 'lucas-the-agent-master'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{\"directory_name\": \"lucas-the-agent-master\"}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: lucas-the-agent-master: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mFolder 'lucas-the-agent-master' has been created successfully.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Create a folder called 'lucas-the-agent-master'.\",\n",
       " 'output': \"Folder 'lucas-the-agent-master' has been created successfully.\"}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from langchain.tools import tool\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "import json\n",
    "\n",
    "@tool\n",
    "def create_directory(directory_name):\n",
    "    \"\"\"Function that creates a directory given a directory name.\"\"\"\"\"\n",
    "    subprocess.run([\"mkdir\", directory_name])\n",
    "    return json.dumps({\"directory_name\": directory_name})\n",
    "\n",
    "\n",
    "tools = [create_directory]\n",
    "\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "    (\"system\",\"You are very powerful assistant that helps\\\n",
    "                users perform tasks in the terminal.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "llm_with_tools = llm_chat.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "agent = (\n",
    "{\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "        x[\"intermediate_steps\"]\n",
    "    ),\n",
    "}\n",
    "| prompt\n",
    "| llm_with_tools\n",
    "| OpenAIFunctionsAgentOutputParser())\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "action_input = \"Create a folder called 'lucas-the-agent-master'.\"\n",
    "\n",
    "agent_executor.invoke({\"input\": action_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great! Now, let's walkthrough what is going on here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the custom tool function:\n",
    "```python\n",
    "@tool\n",
    "def create_directory(directory_name):\n",
    "    \"\"\"Function that creates a directory given a directory name.\"\"\"\n",
    "    subprocess.run([\"mkdir\", directory_name])\n",
    "    return json.dumps({\"directory_name\": directory_name})\n",
    "```\n",
    "\n",
    "- Create a list of tools:\n",
    "\n",
    "```python\n",
    "tools = [create_directory]\n",
    "```\n",
    "\n",
    "- Initialize the chat model:\n",
    "\n",
    "```python\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "```\n",
    "\n",
    "- Create a chat prompt template:\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are very powerful assistant that helps users perform tasks in the terminal.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "- Bind the chat model with the tools:\n",
    "\n",
    "```python\n",
    "llm_with_tools = llm_chat.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "```\n",
    "\n",
    "- Define the agent:\n",
    "\n",
    "```python\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "- Create an instance of AgentExecutor:\n",
    "\n",
    "```python\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "```\n",
    "\n",
    "- Invoke the agent with an input:\n",
    "\n",
    "```python\n",
    "action_input = \"Create a folder called 'lucas-the-agent-master'.\"\n",
    "agent_executor.invoke({\"input\": action_input})\n",
    "```\n",
    "\n",
    "In the given setup, the intermediate_steps and agent_scratchpad are used to represent the history of the agent's thought process and the intermediate results generated during that process. Here's a breakdown of each component:\n",
    "\n",
    "• intermediate_steps: This is a sequence of tuples that contains the agent's actions and the corresponding tool outputs at each step of the conversation. It provides a record of the agent's decision-making process and the information it has gathered along the way.\n",
    "\n",
    "• agent_scratchpad: This is a placeholder variable that holds the intermediate_steps in the prompt template. It allows the agent to access and utilize the historical information during its decision-making process.\n",
    "\n",
    "• MessagesPlaceholder: This is a component in the prompt template that acts as a placeholder for the agent_scratchpad. It specifies where the agent_scratchpad should be inserted in the conversation. In the given setup, the MessagesPlaceholder is placed after the user input, indicating that the agent_scratchpad should be included in the conversation after the user's message.\n",
    "\n",
    "\n",
    "By including the intermediate_steps and agent_scratchpad in the prompt template and passing them to the agent, the setup allows the agent to have access to its previous actions and tool outputs, enabling it to make informed decisions and generate more contextually relevant responses.\n",
    "\n",
    "The essence of this script is to define a custom tool function create_directory that creates a directory given a directory name. It initializes an agent with the tool function and a chat model. The agent is then invoked with an input to execute the tool function. The output of the agent is printed.\n",
    "\n",
    "Don't worry about understanding the syntax, let's just discuss at a higher level what components are at play here:\n",
    "\n",
    "- `@tool` decorator: transforms a regular function into a usable tool for a LangChain-based agent. \n",
    "- `ChatOpenAI` - LangChain's implementation of the OpenAI API for chat models (like `gpt-3.5-turbo-1106`).\n",
    "- `ChatPromptTemplate`: something that allows you to programatically abstract over the chat prompt for the chat model.\n",
    "- `format_tool_to_openai_function`: LangChain's method to convert a tool to one formatted according to OpenAI's scheme.\n",
    "- `format_to_openai_function_message`: LangChain's method to format a message to the OpenAI function calling format.\n",
    "- `OpenAIFunctionsAgentOutputParser`: LangChain's output parsing for outputs of an OpenAI function.\n",
    "- `agent = ... | ... | ... |`: Langchain's Expression Language interface which allows you to build these complex and cool agents by giving you a simple interface that uses the Unix pipe symbol `|` to compose building blocks like models and prompts.\n",
    "- `AgentExecutor`: LangChain framework that serves as the runtime for an agent. It is responsible for executing the agent's decision-making process, invoking tools, and generating responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use an agent we want that agent to have access to its previous outputs and decision-making process in order for it to make more informed decisions. Therefore, LangChain allows you to set all that up yourself so you have ultimate control over what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next notebook we'll dive into the basics of LangChain for building Agents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [HuggingGPT](https://github.com/microsoft/JARVIS)\n",
    "- [Gen Agents](https://arxiv.org/pdf/2304.03442.pdf)\n",
    "- [WebGPT](https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-answering-with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22)\n",
    "- [LangChain](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [OpenAI](https://openai.com/)\n",
    "- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n",
    "- [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)\n",
    "- [BabyAGI](https://github.com/yoheinakajima/babyagi)\n",
    "- [Karpathy on Agents](https://www.youtube.com/watch?v=fqVLjtvWgq8)\n",
    "- [ReACT Paper](https://arxiv.org/abs/2210.03629)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
