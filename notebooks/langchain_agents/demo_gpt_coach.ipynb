{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Agent for Automated Planning and Exercise Program Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.11.8-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-5.0.0-cp311-cp311-macosx_11_0_universal2.whl.metadata (6.7 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting tabulate (from unstructured)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.9.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (0.6.3)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (1.26.2)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.6.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: backoff in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (4.9.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.15.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: wrapt in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from requests->unstructured) (2023.11.17)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->unstructured)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Downloading unstructured-0.11.8-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m98.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.9.0-py2.py3-none-any.whl (397 kB)\n",
      "Downloading lxml-5.0.0-cp311-cp311-macosx_11_0_universal2.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m49.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:06\u001b[0mm\n",
      "\u001b[?25hDownloading python_iso639-2024.1.2-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m48.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.6.1-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m93.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.15.1-py3-none-any.whl (20 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: filetype, tabulate, rapidfuzz, python-magic, python-iso639, lxml, langdetect, jsonpath-python, joblib, emoji, charset-normalizer, chardet, nltk, unstructured-client, unstructured\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "Successfully installed chardet-5.2.0 charset-normalizer-3.3.2 emoji-2.9.0 filetype-1.2.0 joblib-1.3.2 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.0.0 nltk-3.8.1 python-iso639-2024.1.2 python-magic-0.4.27 rapidfuzz-3.6.1 tabulate-0.9.0 unstructured-0.11.8 unstructured-client-0.15.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U langchain\n",
    "# !pip install openai-whisper\n",
    "# !pip install pydub\n",
    "# !pip install moviepy\n",
    "# !pip install pytube\n",
    "# !pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mresources/\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organize the resources.\n",
    "\n",
    "Resources involve:\n",
    "\n",
    "- Personal notes on objectives and goals (maybe this should be in the systems prompt?)\n",
    "- PDFs for books and papers related to health, muscle building, strength training, wrestling and grappling resources\n",
    "- Table with information about my progress\n",
    "- Transcripts of Youtube videos (built programatically from the Youtube URLs)\n",
    "- Exercise descriptions (preferably with reference resources)\n",
    "- Perhaps medically related information?\n",
    "- Time available? (dynamic variable)\n",
    "- Energy available (dynamic variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting youtube_urls.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile youtube_urls.txt\n",
    "https://www.youtube.com/watch?v=TrLV03TYocs\n",
    "https://www.youtube.com/watch?\n",
    "https://www.youtube.com/watch?v=0dB7JjpBMtI\n",
    "https://youtu.be/pyWiE7oDJQ8?si=aq0TriysrRB8XUDl\n",
    "https://www.youtube.com/shorts/pzS0L9CllwM\n",
    "https://www.youtube.com/shorts/UX0k3sfiJHg\n",
    "https://www.youtube.com/shorts/4kfVHtwm_TY\n",
    "https://www.youtube.com/watch?v=fW79HCBIY-c\n",
    "https://www.youtube.com/watch?v=0dB7JjpBMtI\n",
    "https://www.youtube.com/watch?v=8y2HSu6llZE\n",
    "https://www.youtube.com/watch?v=tf__0rFBlpc\n",
    "https://www.youtube.com/watch?v=pyGvRGATPHs\n",
    "https://www.youtube.com/watch?v=YeIu6CX5AOo\n",
    "https://www.youtube.com/watch?v=fUOEdGmgy98˚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process all these youtube videos in the following manner:\n",
    "\n",
    "1. Download\n",
    "2. Transcribe\n",
    "3. Save Transcription to .txt file\n",
    "4. Delete downloaded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('youtube_urls.txt') as f:\n",
    "    urls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=TrLV03TYocs\\n',\n",
       " 'https://www.youtube.com/watch?v=jb3lme_KIjo\\n',\n",
       " 'https://www.youtube.com/watch?\\n',\n",
       " 'https://www.youtube.com/watch?v=0dB7JjpBMtI\\n',\n",
       " 'https://youtu.be/pyWiE7oDJQ8?si=aq0TriysrRB8XUDl\\n',\n",
       " 'https://www.youtube.com/shorts/pzS0L9CllwM\\n',\n",
       " 'https://www.youtube.com/shorts/UX0k3sfiJHg\\n',\n",
       " 'https://www.youtube.com/shorts/4kfVHtwm_TY\\n',\n",
       " 'https://www.youtube.com/watch?v=fW79HCBIY-c\\n',\n",
       " 'https://www.youtube.com/watch?v=0dB7JjpBMtI\\n',\n",
       " 'https://www.youtube.com/watch?v=8y2HSu6llZE\\n',\n",
       " 'https://www.youtube.com/watch?v=tf__0rFBlpc\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process these youtube videos we will use a set of tools from the youtube_utils.py script in the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.youtube.com/watch?v=TrLV03TYocs',\n",
    " 'https://www.youtube.com/watch?v=jb3lme_KIjo',\n",
    " 'https://www.youtube.com/watch?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in youtube_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in youtube_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "regex_search: could not find match for (?:v=|\\/)([0-9A-Za-z_-]{11}).*\n",
      "Failed to download/transcribe this video: https://www.youtube.com/watch?\n"
     ]
    }
   ],
   "source": [
    "for i, url in enumerate(urls):\n",
    "    try:\n",
    "        transcription = transcribe_youtube_video(url)\n",
    "        with open(f\"youtube_vid_{i}.txt\", \"w\") as f:\n",
    "            f.write(transcription)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to download/transcribe this video: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_vid_0.txt youtube_vid_1.txt\n"
     ]
    }
   ],
   "source": [
    "# we check in with the downloaded transcriptions\n",
    "!ls youtube_vid_*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we delete the downloaded videos to avoid storage issues\n",
    "\n",
    "!rm ./*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing web_articles.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile web_articles.txt\n",
    "\n",
    "https://www.healthline.com/health/uneven-shoulders?utm_source=pocket_mylist&c=444733912517#exercises\n",
    "https://journals.lww.com/nsca-scj/fulltext/2011/12000/strength_and_conditioning_for_grappling_sports.4.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For web article we will scrape the contents of the web article page and save it locally to .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URL '': No scheme supplied. Perhaps you meant https://?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_text(url: str):\n",
    "    # Send a GET request to the webpage\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract all text from the webpage\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "            # Print the extracted text\n",
    "            return page_text\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\"\n",
    "\n",
    "with open(\"web_articles.txt\", \"r\") as f:\n",
    "    web_article_urls = f.readlines()\n",
    "\n",
    "for i,url in enumerate(web_article_urls):\n",
    "    try:\n",
    "        text = scrape_text(url)\n",
    "        with open(f\"web_article_{i}.txt\", \"w\") as f:\n",
    "            f.write(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Failed to download/transcribe this web article: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web_article_0.txt web_article_1.txt web_article_2.txt\n"
     ]
    }
   ],
   "source": [
    "!ls web_article_*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing personal_notes.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile personal_notes.txt\n",
    "\n",
    "- Create a warm up just based on a combination of shuffle step dancing and footwork like dominick cruz and Vasily Lomachenko\n",
    "- Create a wrestling movement practice! Granby roll, uchimata, double leg shot, sweep single shot, getting out of bottom, footwork, sprawl, inverting.\n",
    "- Create drills/games/challenges to become an expert headlock type grips.\n",
    "- More hip mobility and strength\n",
    "- Work on slide by muscles: '''Quadriceps: Essential for explosiveness and leg drive.\n",
    "Hamstrings: Provide stability and power during the slide.\n",
    "Calves: Assist with balance and quick footwork.\n",
    "Abdominals: Core strength is crucial for balance and twisting.\n",
    "Deltoids: Important for controlling the opponent's upper body.\n",
    "Biceps and Triceps: Aid in controlling the opponent's arms.\n",
    "Pectoralis Major: Helps with upper body control and stability.\n",
    "Latissimus Dorsi: Provides strength in pulling and twisting.\n",
    "Trapezius: Supports the shoulders and upper body control.\n",
    "Rhomboids: Assist with shoulder blade stability.\n",
    "Erector Spinae: Support the lower back during the move.\n",
    "Gluteus Maximus: Contributes to hip movement.\n",
    "Adductors: Assist with leg control and balance.\n",
    "Hip Flexors: Important for hip movement and balance.\n",
    "Serratus Anterior: Aids in stabilizing the shoulder girdle.\n",
    "Forearm muscles: Assist with grip and control.\n",
    "Neck muscles: Support head movement and stability.''' \n",
    "- Wrestling: '''\n",
    "    - mat returns\n",
    "    - mat return fail to arm in/high wrist guilhotine variation\n",
    "    - front headlock throw\n",
    "    - front headlock throw to high elbow/high wrist guilhotine while controlling the arm\n",
    "- Guard\n",
    "    - k guard to back side 50/50 (and finish!)\n",
    "    - fake straight footlock to cross ashi\n",
    "    - reverse delariva to cool cross ashi entry like in here\n",
    "- defense\n",
    "    - buggy chokes from everywhere (setups, like in the body lock pass) \n",
    "- reverse grip when loose passing \n",
    "- general\n",
    "    - chaining submissions from top and bottom! Wrestling to submission, guard to submission!\n",
    "- false reap to the back when opponent turns his back'''\n",
    "- Jiu Jitsu Warmup: '''\n",
    "Running/jumping jacks/rowing (5m)\n",
    "\n",
    "- rubber band warmups (quality reps for each) (max 5m)\n",
    "   - snap down\n",
    "   - underhook \n",
    "   - slideby\n",
    "   - uchikomi \n",
    "\n",
    "Hand fighting setups (5m)\n",
    "    - undertook to the back (3x quality reps)\n",
    "    - slide by (3x quality reps)\n",
    "    - snap down (3x quality reps)\n",
    "    - 2-1 (3x quality reps)\n",
    "    - inside ties (3x quality reps)\n",
    "\n",
    "- Hand fighting (3x1m)\n",
    "\n",
    "Entries/Lifts/Throws\n",
    "    - Uchimata shadow (2x1m)\n",
    "    - Double leg entries (2x1m)\n",
    "    - Single leg entries (2x1m)\n",
    "    - Lifting from the back (2x1m)\n",
    "\n",
    "- Turtle escapes (3x all quality reps) - 3-5m max\n",
    "    - wrist in the pocket\n",
    "    - switch\n",
    "    - granby roll '''\n",
    "- Medicine ball exercises to build strength for chokes etc...\n",
    "- Practice the arch of the spine\n",
    "- Kettlebell + towel exercises for grip and obliques\n",
    "- Try that squat with the weight on your forearms\n",
    "- Learn the macaquinho movement properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm web_articles.txt youtube_urls.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move all the .txt files to a `resources` folder so tha we can load everything directly from that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: resources: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv *.txt ./resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal_notes.txt web_article_1.txt  youtube_vid_0.txt  youtube_vid_1.txt\n"
     ]
    }
   ],
   "source": [
    "!ls resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents\n",
    "\n",
    "# !pip install -U langchain langchain-community langchainhub openai faiss-cpu\n",
    "\n",
    "# !pip install langchainhub\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"./resources/\")\n",
    "documents = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a tool for our retriever. The main things we need to pass in are a name for the retriever as well as a description. These will both be used by the language model, so they should be informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_exercise_docs\",\n",
    "    \"Searches and retuens excerpts from notes, youtube transcripts and web articles about exercising workouts, strength training, grappling training as well as my personal objectives and goals.\"\n",
    ")\n",
    "\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Constructor\n",
    "Here, we will use the high level create_openai_tools_agent API to construct the agent.\n",
    "\n",
    "Notice that beside the list of tools, the only thing we need to pass in is a language model to use. Under the hood, this agent is using the OpenAI tool-calling capabilities, so we need to use a ChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm_chat = ChatOpenAI(model=\"gpt-4-preview-1106\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm_chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"hi, I am Lucas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Lucas! How can I assist you today?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What are my personal goals regarding exercise and fighting?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are your personal goals regarding exercise and fighting:\\n\\n1. Create a warm-up based on a combination of shuffle step dancing and footwork like Dominick Cruz and Vasily Lomachenko.\\n2. Develop a wrestling movement practice, including Granby roll, uchimata, double leg shot, sweep single shot, getting out of bottom, footwork, sprawl, inverting.\\n3. Create drills/games/challenges to become an expert in headlock type grips.\\n4. Improve hip mobility and strength.\\n5. Work on slide by muscles, including quadriceps, hamstrings, calves, abdominals, deltoids, biceps and triceps, pectoralis major, latissimus dorsi, trapezius, rhomboids, erector spinae, gluteus maximus, adductors, hip flexors, serratus anterior, forearm muscles, and neck muscles.\\n6. Practice wrestling techniques such as mat returns, front headlock throw, and guard techniques.\\n7. Develop a Jiu Jitsu warmup routine, including running/jumping jacks/rowing, rubber band warmups, hand fighting setups, entries/lifts/throws, and turtle escapes.\\n8. Incorporate medicine ball exercises to build strength for chokes etc.\\n9. Practice the arch of the spine.\\n10. Use kettlebell + towel exercises for grip and obliques.\\n11. Try squatting with the weight on your forearms.\\n12. Learn the macaquinho movement properly.\\n13. Improve your foot protocol by walking backward with intention through the big toe on every step.\\n14. Develop a healthy spine and strong posterior chain through bridge exercises.\\n15. Open up the anterior chain muscles, improve breathing, strengthen the posterior chain of muscles, improve posture, and increase focus through bridge exercises.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the information from your notes and other resources, here's a 45-minute workout routine that incorporates your interests and exercise routines:\n",
       "\n",
       "**Warm-up (5 minutes)**\n",
       "\n",
       "- Start with a combination of shuffle step dancing and footwork like Dominick Cruz and Vasily Lomachenko.\n",
       "\n",
       "**Strength Training (20 minutes)**\n",
       "\n",
       "- **Shoulder Bridge (3 sets of 15-30 seconds)**: This exercise strengthens the posterior chain and increases thoracic rotation. It's also known as the Jiu-Jitsu bridge or Upa in martial arts.\n",
       "\n",
       "- **Tabletop Bridge (3 sets of 15-30 seconds)**: This exercise strengthens the abdominals and glutes while improving shoulder mobility.\n",
       "\n",
       "- **Back Bridge (3 sets of 15-30 seconds)**: This iconic exercise is used in martial arts, gymnastics, calisthenics, and yoga.\n",
       "\n",
       "- **Dumbbell Exercises (3 sets of 12 repetitions)**: Reverse fly and overhead external shoulder rotation exercises can help build strength in your shoulders and upper body.\n",
       "\n",
       "**Grappling Training (15 minutes)**\n",
       "\n",
       "- Practice wrestling movements like Granby roll, uchimata, double leg shot, sweep single shot, getting out of bottom, footwork, sprawl, and inverting.\n",
       "\n",
       "- Work on slide by muscles and headlock type grips.\n",
       "\n",
       "- Practice Jiu Jitsu movements like snap down, underhook, slideby, uchikomi, and hand fighting setups.\n",
       "\n",
       "**Cool Down (5 minutes)**\n",
       "\n",
       "- Finish with a 5-minute backward walk focusing on the big toe with each step. This can help strengthen your feet and leg muscles.\n",
       "\n",
       "Remember, consistency is key in seeing progress in your workouts. Make sure to adjust the routine as needed to fit your current fitness level and goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"If you were to create a workout based on all the information present in my notes regarding \\\n",
    "        my interests and interesting exercise routines and workouts.\\\n",
    "        Considering I only have 45 minutes a day, what work out would you recommend?\"\n",
    "})\n",
    "\n",
    "Markdown(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible extensions of this agent could be to integrate papers, web articles, youtube videos, transcripts and more. We could also do some fancy prompt engineering to get the best possible performance from the agent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
