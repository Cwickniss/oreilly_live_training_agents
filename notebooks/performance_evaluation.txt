The performance of the Tree of Thoughts (ToT) technique was evaluated through a series of experiments involving tasks that are challenging even for state-of-the-art language models like GPT-4. The evaluation focused on three main tasks: Game of 24, Creative Writing, and Mini Crosswords.

1. **Game of 24 and Creative Writing**: In these tasks, ToT was used to generate coherent outputs by sampling multiple plans and voting to decide the best plan. The performance was measured by comparing the coherency scores of the outputs generated by ToT against those generated by other methods like Input-Output (IO) prompting and Chain-of-Thought (CoT) prompting. ToT showed superior results by achieving higher coherency scores.

2. **Mini Crosswords**: This task involved solving 5x5 mini crosswords, which is a more complex problem requiring deeper search. The evaluation considered three levels of success: the portion of correct letters, words, and games. ToT was compared against baseline methods, and its performance was measured by the success rate in correctly solving the crosswords. ToT achieved higher success rates compared to other methods, demonstrating its effectiveness in handling complex search problems.

The evaluation also involved systematic ablations to understand the impact of different components of the ToT framework on performance. The results showed that ToT's ability to explore and evaluate different thoughts systematically contributed to its superior performance across the tasks.