{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a research Agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install \"langchain[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if running locally\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# Or if you are in Colab, uncoment below and add your api key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE: Create a simple agent that performs a productive task, whatever that means for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.quora.com/Why-do-pancakes-from-restaurants-taste-so-much-better-than-the-pancakes-I-make-at-home',\n",
       " 'https://www.reddit.com/r/Showerthoughts/comments/12eccux/pancakes_is_an_excuse_to_eat_dessert_for_breakfast/',\n",
       " 'https://www.buzzfeed.com/ryankincaid/stacks-on-stacks',\n",
       " 'https://www.prnewswire.com/news-releases/packaged-facts-still-room-for-pancakes-and-waffles-at-americas-breakfast-table-300317750.html',\n",
       " 'https://www.fitday.com/fitness-articles/nutrition/healthy-eating/healthy-breakfast-pancakes-vs-waffles.html',\n",
       " 'https://www.stlouisfed.org/education/exploring-economics-video-series/perfect-breakfast',\n",
       " 'https://www.snackandbakery.com/articles/94837-state-of-the-industry-2020-breakfast-products-combine-nutrition-and-good-taste',\n",
       " 'https://health.ucdavis.edu/blog/good-food/why-is-breakfast-important-our-dietitian-gives-healthy-breakfast-ideas/2022/04',\n",
       " 'https://www.kingarthurbaking.com/blog/2021/10/26/best-pancake-tips']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.results(query)\n",
    "    results = output[\"organic_results\"]\n",
    "    return [r[\"link\"] for r in results]\n",
    "\n",
    "web_search(\"Current resources on why pancakes are the best breakfast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'input']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       " 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'input_variables': ['agent_scratchpad', 'input'],\n",
       " 'input_types': {'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       "  'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'metadata': None,\n",
       " 'tags': None,\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       "  MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       "  MessagesPlaceholder(variable_name='agent_scratchpad')],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build an agent I need to do 2 essential things:\n",
    "\n",
    "1. Connect a model to tools\n",
    "2. Set up a loop in which the model continuously tries to solve the problem by either just calling the llm or calling a tool, observing the result and repeating until finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "\n",
    "tools = [web_search]\n",
    "\n",
    "agent = create_openai_tools_agent(llm_chat, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'resources to learn new languages'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://nymag.com/strategist/article/how-to-learn-languages-at-home.html', 'https://www.theintrepidguide.com/top-language-learning-resources/', 'https://www.lingualift.com/blog/best-language-learning-resources/', 'https://www.reddit.com/r/languagelearning/comments/uhiuab/what_are_apps_or_websites_where_you_can_learn/', 'https://www.quora.com/What-resources-do-you-use-to-learn-languages', 'https://libguides.csudh.edu/modernlanguages/freeresources', 'https://www.alllanguageresources.com/', 'https://www.fluentu.com/blog/free-language-learning-websites/']\u001b[0m\u001b[32;1m\u001b[1;3mI found some resources that can help you learn new languages:\n",
      "\n",
      "1. [How to Learn Languages at Home - NYMag](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\n",
      "2. [Top Language Learning Resources - The Intrepid Guide](https://www.theintrepidguide.com/top-language-learning-resources/)\n",
      "3. [Best Language Learning Resources - Lingualift](https://www.lingualift.com/blog/best-language-learning-resources/)\n",
      "4. [Apps or Websites to Learn Languages - Reddit](https://www.reddit.com/r/languagelearning/comments/uhiuab/what_are_apps_or_websites_where_you_can_learn/)\n",
      "5. [Resources for Learning Languages - Quora](https://www.quora.com/What-resources-do-you-use-to-learn-languages)\n",
      "6. [Free Language Learning Resources - CSUDH LibGuides](https://libguides.csudh.edu/modernlanguages/freeresources)\n",
      "7. [All Language Resources](https://www.alllanguageresources.com/)\n",
      "8. [Free Language Learning Websites - FluentU](https://www.fluentu.com/blog/free-language-learning-websites/)\n",
      "\n",
      "You can explore these resources to find the best fit for your language learning journey.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good resources to learn about learning new languages?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'I found some resources that can help you learn new languages:\\n\\n1. [How to Learn Languages at Home - NYMag](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\\n2. [Top Language Learning Resources - The Intrepid Guide](https://www.theintrepidguide.com/top-language-learning-resources/)\\n3. [Best Language Learning Resources - Lingualift](https://www.lingualift.com/blog/best-language-learning-resources/)\\n4. [Apps or Websites to Learn Languages - Reddit](https://www.reddit.com/r/languagelearning/comments/uhiuab/what_are_apps_or_websites_where_you_can_learn/)\\n5. [Resources for Learning Languages - Quora](https://www.quora.com/What-resources-do-you-use-to-learn-languages)\\n6. [Free Language Learning Resources - CSUDH LibGuides](https://libguides.csudh.edu/modernlanguages/freeresources)\\n7. [All Language Resources](https://www.alllanguageresources.com/)\\n8. [Free Language Learning Websites - FluentU](https://www.fluentu.com/blog/free-language-learning-websites/)\\n\\nYou can explore these resources to find the best fit for your language learning journey.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What are good resources to learn about learning new languages?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt's important to gather information from reliable sources to answer this question.\n",
      "Action: web_search\n",
      "Action Input: \"best way to learn good programming practices\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.reddit.com/r/learnprogramming/comments/6bv3ux/how_do_you_practice_programming/', 'https://www.quora.com/How-can-I-learn-the-best-practices-in-programming', 'https://www.thinkful.com/blog/coding-best-practices/', 'https://www.educative.io/blog/coding-best-practices', 'https://flatironschool.com/blog/best-websites-to-practice-coding-for-beginners/', 'https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://codesigningstore.com/ultimate-programming-best-practices-guide', 'https://www.browserstack.com/guide/coding-standards-best-practices', 'https://www.wikihow.com/Practice-Programming']\u001b[0m\u001b[32;1m\u001b[1;3mThere are various resources available that can provide insights on good programming practices.\n",
      "Action: web_search\n",
      "Action Input: \"coding best practices\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://en.wikipedia.org/wiki/Coding_best_practices', 'https://www.browserstack.com/guide/coding-standards-best-practices', 'https://www.educative.io/blog/coding-best-practices', 'https://mitcommlab.mit.edu/broad/commkit/best-practices-for-coding-organization-and-documentation/', 'https://www.reddit.com/r/java/comments/2z58la/what_are_good_coding_practices_that_you_wish/', 'https://www.appacademy.io/blog/python-coding-best-practices', 'https://medium.com/@josueparra2892/20-best-programming-practices-407df688b96e']\u001b[0m\u001b[32;1m\u001b[1;3mThere are many articles and guides available that can help in learning good programming practices.\n",
      "Action: web_search\n",
      "Action Input: \"programming best practices guide\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.browserstack.com/guide/coding-standards-best-practices', 'https://www.thinkful.com/blog/coding-best-practices/', 'https://en.wikipedia.org/wiki/Coding_best_practices', 'https://www.educative.io/blog/coding-best-practices', 'https://softwareengineering.stackexchange.com/questions/196706/creating-a-coding-standards-document', 'https://codesigningstore.com/ultimate-programming-best-practices-guide', 'https://mitcommlab.mit.edu/broad/commkit/best-practices-for-coding-organization-and-documentation/', 'https://medium.com/@josueparra2892/20-best-programming-practices-407df688b96e']\u001b[0m\u001b[32;1m\u001b[1;3mThere is a wealth of information available on coding best practices and programming guides that can help in learning good programming practices.\n",
      "Final Answer: The best way to learn good programming practices is to study coding best practices guides and resources available online.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best way to learn good programming practices?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The best way to learn good programming practices is to study coding best practices guides and resources available online.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm_chat, tools, prompt)\n",
    "\n",
    "react_agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "react_agent_executor.invoke({\"input\": \"What is the best way to learn good programming practices?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build this same agent but using a more in depth approach going one level down in the abstraction layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go down the latter of abstraction and build this same agent but leveraging the lower-level capabilities of LangChain's LCEL language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(model=\"gpt-3.5-turbo-16k\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.results(query)\n",
    "    results = output[\"organic_results\"]\n",
    "    return [r[\"link\"] for r in results]\n",
    "\n",
    "\n",
    "tools = [web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant.\\\n",
    "            Given a user query you will perform research on the \\\n",
    "                topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bind tools to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.convert_to_openai import format_tool_to_openai_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have to do is import two last utility functions:\n",
    "- a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, \n",
    "- and a component for converting the output message into an agent action/agent finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'best open source LLM'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/blog/top-open-source-llms', 'https://github.com/Hannibal046/Awesome-LLM', 'https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/', 'https://www.width.ai/post/the-best-open-source-llms', 'https://blog.n8n.io/open-source-llm/', 'https://klu.ai/blog/open-source-llm-models', 'https://github.com/eugeneyan/open-llms', 'https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024', 'https://www.youtube.com/watch?v=L6nnNTVX-VI']\u001b[0m\u001b[32;1m\u001b[1;3mThere are several open source LLM (Language Model) projects available. Here are some resources that can help you find the best open source LLM:\n",
      "\n",
      "1. [DataCamp Blog](https://www.datacamp.com/blog/top-open-source-llms): This blog post provides a list of top open source LLM projects.\n",
      "\n",
      "2. [Awesome-LLM GitHub Repository](https://github.com/Hannibal046/Awesome-LLM): This GitHub repository contains a curated list of open source LLM projects.\n",
      "\n",
      "3. [Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/): This Reddit thread discusses the top open source projects in the LLM space.\n",
      "\n",
      "4. [Width.ai Blog](https://www.width.ai/post/the-best-open-source-llms): This blog post highlights the best open source LLM projects.\n",
      "\n",
      "5. [n8n.io Blog](https://blog.n8n.io/open-source-llm/): This blog post discusses open source LLM models and their applications.\n",
      "\n",
      "6. [Klu.ai Blog](https://klu.ai/blog/open-source-llm-models): This blog post explores open source LLM models and their features.\n",
      "\n",
      "7. [Open-LLMs GitHub Repository](https://github.com/eugeneyan/open-llms): This GitHub repository contains open source LLM models.\n",
      "\n",
      "8. [Techopedia Article](https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024): This article lists the 6 best open source LLMs to watch out for in 2024.\n",
      "\n",
      "Please note that the \"best\" open source LLM may vary depending on your specific requirements and use case. It is recommended to explore these resources and evaluate the projects based on your needs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [OpenAIToolAgentAction(tool='web_search', tool_input={'query': 'best open source LLM'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source LLM'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_HiVnPSa0aULBRoUBQ8nBiVss', 'function': {'arguments': '{\\n  \"query\": \"best open source LLM\"\\n}', 'name': 'web_search'}, 'type': 'function'}]})], tool_call_id='call_HiVnPSa0aULBRoUBQ8nBiVss')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_HiVnPSa0aULBRoUBQ8nBiVss', 'function': {'arguments': '{\\n  \"query\": \"best open source LLM\"\\n}', 'name': 'web_search'}, 'type': 'function'}]})]},\n",
       " {'steps': [AgentStep(action=OpenAIToolAgentAction(tool='web_search', tool_input={'query': 'best open source LLM'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source LLM'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_HiVnPSa0aULBRoUBQ8nBiVss', 'function': {'arguments': '{\\n  \"query\": \"best open source LLM\"\\n}', 'name': 'web_search'}, 'type': 'function'}]})], tool_call_id='call_HiVnPSa0aULBRoUBQ8nBiVss'), observation=['https://www.datacamp.com/blog/top-open-source-llms', 'https://github.com/Hannibal046/Awesome-LLM', 'https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/', 'https://www.width.ai/post/the-best-open-source-llms', 'https://blog.n8n.io/open-source-llm/', 'https://klu.ai/blog/open-source-llm-models', 'https://github.com/eugeneyan/open-llms', 'https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024', 'https://www.youtube.com/watch?v=L6nnNTVX-VI'])],\n",
       "  'messages': [FunctionMessage(content='[\"https://www.datacamp.com/blog/top-open-source-llms\", \"https://github.com/Hannibal046/Awesome-LLM\", \"https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/\", \"https://www.width.ai/post/the-best-open-source-llms\", \"https://blog.n8n.io/open-source-llm/\", \"https://klu.ai/blog/open-source-llm-models\", \"https://github.com/eugeneyan/open-llms\", \"https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024\", \"https://www.youtube.com/watch?v=L6nnNTVX-VI\"]', name='web_search')]},\n",
       " {'output': 'There are several open source LLM (Language Model) projects available. Here are some resources that can help you find the best open source LLM:\\n\\n1. [DataCamp Blog](https://www.datacamp.com/blog/top-open-source-llms): This blog post provides a list of top open source LLM projects.\\n\\n2. [Awesome-LLM GitHub Repository](https://github.com/Hannibal046/Awesome-LLM): This GitHub repository contains a curated list of open source LLM projects.\\n\\n3. [Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/): This Reddit thread discusses the top open source projects in the LLM space.\\n\\n4. [Width.ai Blog](https://www.width.ai/post/the-best-open-source-llms): This blog post highlights the best open source LLM projects.\\n\\n5. [n8n.io Blog](https://blog.n8n.io/open-source-llm/): This blog post discusses open source LLM models and their applications.\\n\\n6. [Klu.ai Blog](https://klu.ai/blog/open-source-llm-models): This blog post explores open source LLM models and their features.\\n\\n7. [Open-LLMs GitHub Repository](https://github.com/eugeneyan/open-llms): This GitHub repository contains open source LLM models.\\n\\n8. [Techopedia Article](https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024): This article lists the 6 best open source LLMs to watch out for in 2024.\\n\\nPlease note that the \"best\" open source LLM may vary depending on your specific requirements and use case. It is recommended to explore these resources and evaluate the projects based on your needs.',\n",
       "  'messages': [AIMessage(content='There are several open source LLM (Language Model) projects available. Here are some resources that can help you find the best open source LLM:\\n\\n1. [DataCamp Blog](https://www.datacamp.com/blog/top-open-source-llms): This blog post provides a list of top open source LLM projects.\\n\\n2. [Awesome-LLM GitHub Repository](https://github.com/Hannibal046/Awesome-LLM): This GitHub repository contains a curated list of open source LLM projects.\\n\\n3. [Reddit Thread](https://www.reddit.com/r/LocalLLaMA/comments/17jmpn8/what_are_top_open_source_projects_in_llm_space/): This Reddit thread discusses the top open source projects in the LLM space.\\n\\n4. [Width.ai Blog](https://www.width.ai/post/the-best-open-source-llms): This blog post highlights the best open source LLM projects.\\n\\n5. [n8n.io Blog](https://blog.n8n.io/open-source-llm/): This blog post discusses open source LLM models and their applications.\\n\\n6. [Klu.ai Blog](https://klu.ai/blog/open-source-llm-models): This blog post explores open source LLM models and their features.\\n\\n7. [Open-LLMs GitHub Repository](https://github.com/eugeneyan/open-llms): This GitHub repository contains open source LLM models.\\n\\n8. [Techopedia Article](https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024): This article lists the 6 best open source LLMs to watch out for in 2024.\\n\\nPlease note that the \"best\" open source LLM may vary depending on your specific requirements and use case. It is recommended to explore these resources and evaluate the projects based on your needs.')]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"What is the current best open source LLM available?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we want the agent to actually read the links and return a research report rather than just the urls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_text(url: str):\n",
    "    \"\"\"Scrapes the text from a given URL and returns it.\"\"\"\n",
    "    # Send a GET request to the webpage\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract all text from the webpage\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "            # Print the extracted text\n",
    "            return page_text[:10000]\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [web_search, scrape_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant. Given a user query you will perform research on the topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"Scrape and summarize the contents from these urls: {input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://towardsdatascience.com/deploying-hugging-face-models-to-production-guide-1e7db0e5bf3f'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mFailed to retrieve the webpage: Status code 403\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://medium.com/swlh/deploying-transformers-in-production-2021-7b4f7f1f5f3c'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mFailed to retrieve the webpage: Status code 403\u001b[0m\u001b[32;1m\u001b[1;3mI encountered an issue while trying to scrape the content from the provided URLs. The status code 403 indicates that access to the webpages is forbidden. \n",
      "\n",
      "Would you like me to attempt to search for alternative sources that discuss the current best practices to deploy LLM agents to production?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the current best practices to deploy LLM agents to production?',\n",
       " 'output': 'I encountered an issue while trying to scrape the content from the provided URLs. The status code 403 indicates that access to the webpages is forbidden. \\n\\nWould you like me to attempt to search for alternative sources that discuss the current best practices to deploy LLM agents to production?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What are the current best practices to deploy LLM agents to production?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encounter a few issues when we try to just add the scrape function to the agent without any other consideration. \n",
    "How about we make this better by improving the inner chain of the agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'best practices to deploy LLM agents to production'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.qwak.com/post/best-practices-when-deploying-llms-in-production', 'https://www.linkedin.com/pulse/deploying-llms-production-anatomy-llm-applications-xenonstack', 'https://www.reddit.com/r/MachineLearning/comments/16fklqj/discussion_how_to_deploy_llm_in_production/', 'https://arize.com/blog-course/large-language-model-llm-deployment/', 'https://www.youtube.com/watch?v=NRjUMB9BrhQ', 'https://huyenchip.com/2023/04/11/llm-engineering.html', 'https://aws.amazon.com/blogs/machine-learning/learn-how-to-build-and-deploy-tool-using-llm-agents-using-aws-sagemaker-jumpstart-foundation-models/', 'https://www.seldon.io/deploying-large-language-models-in-production']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some current best practices for deploying LLM agents to production:\n",
      "\n",
      "1. Understand the requirements: Before deploying an LLM agent, it is important to understand the specific requirements of your application. This includes considering factors such as the size of the model, the computational resources needed, and the expected workload.\n",
      "\n",
      "2. Model selection and fine-tuning: Choose the right LLM model for your application. Consider factors such as model size, performance, and compatibility with your infrastructure. Fine-tune the model on your specific dataset to improve its accuracy and performance.\n",
      "\n",
      "3. Infrastructure considerations: Ensure that your infrastructure can handle the computational requirements of the LLM agent. This may involve using high-performance GPUs or distributed computing resources. Consider using cloud-based solutions for scalability and flexibility.\n",
      "\n",
      "4. Data preprocessing and storage: Preprocess your data to ensure it is in the right format for the LLM agent. Consider using efficient data storage solutions to handle large amounts of data.\n",
      "\n",
      "5. Model deployment: Deploy the LLM agent in a production environment. This may involve setting up a server or cloud-based infrastructure to host the model. Consider using containerization technologies such as Docker for easy deployment and scalability.\n",
      "\n",
      "6. Monitoring and performance optimization: Monitor the performance of the LLM agent in production and optimize it for better efficiency. This may involve fine-tuning hyperparameters, optimizing resource allocation, and implementing caching mechanisms.\n",
      "\n",
      "7. Security and privacy considerations: Ensure that the deployed LLM agent follows best practices for security and privacy. This includes protecting sensitive data, implementing access controls, and regularly updating the model to address security vulnerabilities.\n",
      "\n",
      "8. Continuous improvement: Continuously monitor and evaluate the performance of the LLM agent in production. Collect feedback from users and use it to improve the model and its deployment.\n",
      "\n",
      "Please note that these are general best practices, and the specific requirements and considerations may vary depending on your application and infrastructure. It is recommended to consult with experts and refer to the documentation and resources provided by the LLM framework you are using.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "input1 = \"What are the current best practices to deploy LLM agents to production?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the current best practices to deploy LLM agents to production?',\n",
       " 'chat_history': [HumanMessage(content='What are the current best practices to deploy LLM agents to production?'),\n",
       "  AIMessage(content='Here are some current best practices for deploying LLM agents to production:\\n\\n1. Understand the requirements: Before deploying an LLM agent, it is important to understand the specific requirements of your application. This includes considering factors such as the size of the model, the computational resources needed, and the expected workload.\\n\\n2. Model selection and fine-tuning: Choose the right LLM model for your application. Consider factors such as model size, performance, and compatibility with your infrastructure. Fine-tune the model on your specific dataset to improve its accuracy and performance.\\n\\n3. Infrastructure considerations: Ensure that your infrastructure can handle the computational requirements of the LLM agent. This may involve using high-performance GPUs or distributed computing resources. Consider using cloud-based solutions for scalability and flexibility.\\n\\n4. Data preprocessing and storage: Preprocess your data to ensure it is in the right format for the LLM agent. Consider using efficient data storage solutions to handle large amounts of data.\\n\\n5. Model deployment: Deploy the LLM agent in a production environment. This may involve setting up a server or cloud-based infrastructure to host the model. Consider using containerization technologies such as Docker for easy deployment and scalability.\\n\\n6. Monitoring and performance optimization: Monitor the performance of the LLM agent in production and optimize it for better efficiency. This may involve fine-tuning hyperparameters, optimizing resource allocation, and implementing caching mechanisms.\\n\\n7. Security and privacy considerations: Ensure that the deployed LLM agent follows best practices for security and privacy. This includes protecting sensitive data, implementing access controls, and regularly updating the model to address security vulnerabilities.\\n\\n8. Continuous improvement: Continuously monitor and evaluate the performance of the LLM agent in production. Collect feedback from users and use it to improve the model and its deployment.\\n\\nPlease note that these are general best practices, and the specific requirements and considerations may vary depending on your application and infrastructure. It is recommended to consult with experts and refer to the documentation and resources provided by the LLM framework you are using.')],\n",
       " 'output': 'Here are some current best practices for deploying LLM agents to production:\\n\\n1. Understand the requirements: Before deploying an LLM agent, it is important to understand the specific requirements of your application. This includes considering factors such as the size of the model, the computational resources needed, and the expected workload.\\n\\n2. Model selection and fine-tuning: Choose the right LLM model for your application. Consider factors such as model size, performance, and compatibility with your infrastructure. Fine-tune the model on your specific dataset to improve its accuracy and performance.\\n\\n3. Infrastructure considerations: Ensure that your infrastructure can handle the computational requirements of the LLM agent. This may involve using high-performance GPUs or distributed computing resources. Consider using cloud-based solutions for scalability and flexibility.\\n\\n4. Data preprocessing and storage: Preprocess your data to ensure it is in the right format for the LLM agent. Consider using efficient data storage solutions to handle large amounts of data.\\n\\n5. Model deployment: Deploy the LLM agent in a production environment. This may involve setting up a server or cloud-based infrastructure to host the model. Consider using containerization technologies such as Docker for easy deployment and scalability.\\n\\n6. Monitoring and performance optimization: Monitor the performance of the LLM agent in production and optimize it for better efficiency. This may involve fine-tuning hyperparameters, optimizing resource allocation, and implementing caching mechanisms.\\n\\n7. Security and privacy considerations: Ensure that the deployed LLM agent follows best practices for security and privacy. This includes protecting sensitive data, implementing access controls, and regularly updating the model to address security vulnerabilities.\\n\\n8. Continuous improvement: Continuously monitor and evaluate the performance of the LLM agent in production. Collect feedback from users and use it to improve the model and its deployment.\\n\\nPlease note that these are general best practices, and the specific requirements and considerations may vary depending on your application and infrastructure. It is recommended to consult with experts and refer to the documentation and resources provided by the LLM framework you are using.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
