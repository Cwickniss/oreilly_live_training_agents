{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a research Agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install langchain-openai\n",
    "!pip install langchainhub\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if running locally\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# FILEPATH: /Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly_live_training_agents/notebooks/1.3-intro-agents-with-langchain.ipynb\n",
    "# SET YOUR API KEYS FOR LANGSMITH AND TAVILY TO RUN THIS NOTEBOOK!\n",
    "# langsmith: https://docs.smith.langchain.com/#:~:text=install%20-U%20langsmith-,Create%20an%20API%20key,click%20Create%20API%20Key.,-Setup%20your%20environment\n",
    "# tavily: https://app.tavily.com/sign-in\n",
    "# openai: https://platform.openai.com/docs/quickstart\n",
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"your-api-key\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"your-api-key\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE: Create a simple agent that performs a productive task, whatever that means for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/List_of_highest_mountains_on_Earth',\n",
       "  'content': \"88 | 4\\n87 |\\n86 | 1\\n85 | 8 1\\n84 | 8\\n83 |\\n82 |\\n81 | 8 6 6 2\\n80 | 9 8 5 3 2\\n79 | 5 4 3 3\\n78 | 9 8 7 6 2 2 1 0\\n77 | 9 9 8 8 5 5 4 1 0 0\\n76 |\\n9 7 6 6 4 1 1\\n75 | 7 7 5 5 4 4 4 3 3 1 1\\n74 | 9 9 9 9 7 6 6 6 5 5 3 3 2 2 2 1 1 1 0 0 0\\n73 | 8 8 8 8 8 6 6 5 5 5 4 2 1 1 1 0\\n72 | 9 9 9 8 8 8 8 7 7 6 6 5 4 4 4 3 2 2 1 1 0 0 0 0 0 0 0\\nGallery[edit]\\n1. All peaks 7,000\\xa0m (23,000\\xa0ft) or higher are located in East, Central or South Asia in a rectangle edged by Noshaq (7,492\\xa0m or 24,580\\xa0ft) on the Afghanistan–Pakistan border in the west, Jengish Chokusu (Tuōmù'ěr Fēng, 7,439\\xa0m or 24,406\\xa0ft) on the Kyrgyzstan–Xinjiang border to the north, Gongga Shan (Minya Konka, 7,556\\xa0m or 24,790\\xa0ft) in Sichuan to the east, and Kabru (7,412\\xa0m or 24,318\\xa0ft) on the Sikkim–Nepal border to the south.\\n Mauna Loa (4,169\\xa0m or 13,678\\xa0ft) is the largest mountain on Earth in terms of base area (about 2,000\\xa0sq\\xa0mi or 5,200\\xa0km2) and volume (about 10,000\\xa0cu\\xa0mi or 42,000\\xa0km3), although, due to the intergrade of lava from Kilauea, Hualalai and Mauna Kea, the volume can only be estimated based on surface area and height of the edifice. The two digits to the left of the line are the first two digits of the mountain's height (metres), and each digit to the right of the line represents the third digit of the mountain's height. Ojos del Salado has the greatest rise on Earth: 13,420\\xa0m (44,029\\xa0ft) vertically to the summit[citation needed] from the bottom of the Atacama Trench, which is about 560\\xa0km (350\\xa0mi) away, although most of this rise is not part of the mountain.\\n\"},\n",
       " {'url': 'https://www.treehugger.com/tallest-mountains-in-the-world-5183890',\n",
       "  'content': \"This section of the Himalayas also blends into eastern Nepal, and the region hosts about 2,000 species of flowering plants, 252 species of birds, and a few of the country’s most endangered mammals, such as the snow leopard and the red panda. In 1950, Maurice Herzog and Louis Lachenal were the first to reach the summit (losing their toes and fingers to frostbite as a result), marking the first of the Earth’s 14 eight-thousanders to be scaled; another successful climb wasn’t achieved until 20 years later.\\n The 642-square-mile Manaslu Conservation Area was declared in 1998 to protect the habitats of the 33 mammal species, 110 bird species, 11 butterfly species, and three reptile species that live in the Manaslu region in the North Nepalese Himalayas.\\n Nanga Parbat (Pakistan)\\nNanga Parbat earned its reputation as the “Killer Mountain” after a total of 26 people died attempting to reach the summit before its first ascent in 1953 (a feat completed by Austrian climber Hermann Buhl, who performed the climb without the use of supplementary oxygen).\\n Although it's considered to be another one of the easiest and shortest of the 8000-meter mountains, Shishapangma claimed the life of one of the world’s most famous climbers, Alex Lowe, after an avalanche struck on October 5, 1999 (his body wasn’t recovered until 16 years later).\"},\n",
       " {'url': 'https://www.worldatlas.com/mountains/10-highest-mountains-in-the-world.html',\n",
       "  'content': \"Several studies have revealed that there are approximately 108 high mountains on the planet that reach an elevation of more than 7,200m. A majority of the world’s tallest summits are situated on the edges of the Indian and Eurasian tectonic plates in the countries of Nepal, India, China, and Pakistan and are part of the Himalayan and Karakoram Mountain Ranges. Isla Mujeres\\nThe Deepest Canyons In The United States\\nThe Longest Caves in the World\\n11 of America's Most Famous Geysers\\nThe Deepest Caves In The World\\nIce Sheets\\nAll maps, graphics, flags, photos and original descriptions © 2024 worldatlas.com Mount Dhaulagiri I – 8,167m\\nMount Dhaulagiri I which rises to an elevation of 8,167m is the world’s seventh-highest mountain and the highest mountain situated entirely within the boundaries of the country Nepal. \\xa0 It is situated in the Mahalangur Himal section of the Himalayan Mountain Range, along the boundary between the Khumbu region of Nepal and the Tibet Autonomous Region of China. The Dhaulagiri massif is bounded by the Myagdi Khola River in the southeast and by the tributaries of the Bheri River in the southwest.\"},\n",
       " {'url': 'https://largest.org/nature/mountains/',\n",
       "  'content': 'We’ll also learn some interesting facts about the wildlife that thrives near each one, as well as what each mountain is known for!\\nAnnapurna\\nSource: wikimedia.org\\nThis glorious mountain is technically named Annapurna I and its counterpart, Annapurna II, is also notable as the 16th-highest mountain in the world! Manaslu\\nSource: wikimedia.org\\nAlso known as Kutang, this mountain is located in the Mansiri Himal subrange of the Himalayas and is the highest mountain peak in the Gorkha District of Nepal. Leave a Comment Cancel reply\\nComment\\nRECENT POSTS\\nPOPULAR POSTS\\n10 Largest National Parks\\n5 Largest Owls in the World\\n10 Largest Cat Breeds in the World\\nCATEGORIES\\nSister Sites: Oldest.org | Rarest.org The mountain sits on the border of Pakistan and China and, since it is based on higher ground than Mount Everest, is actually the most prominent mountain in the world!\\n The Himalayan blue sheep, or bharal, isn’t actually a sheep at all but is more closely related to goats!\\nK2\\nSource: wikimedia.org\\nOften called the “Savage Mountain” as a result of its high fatality rate among hikers, this gorgeous mountain towers right at 777 feet beneath Mount Everest.'},\n",
       " {'url': 'https://www.wikiwand.com/en/List_of_highest_mountains_on_Earth',\n",
       "  'content': \"Mauna Loa (4,169\\xa0m or 13,678\\xa0ft) is the largest mountain on Earth in terms of base area (about 2,000\\xa0sq\\xa0mi or 5,200\\xa0km2) and volume (about 10,000\\xa0cu\\xa0mi or 42,000\\xa0km3), although, due to the intergrade of lava from Kilauea, Hualalai and Mauna Kea, the volume can only be estimated based on surface area and height of the edifice. Ojos del Salado has the greatest rise on Earth: 13,420\\xa0m (44,029\\xa0ft) vertically to the summit[citation needed] from the bottom of the Atacama Trench, which is about 560\\xa0km (350\\xa0mi) away, although most of this rise is not part of the mountain.\\n As an extreme example, Ulugh Muztagh on the north Tibetan Plateau is often listed as 7,723\\xa0m (25,338\\xa0ft) to 7,754\\xa0m (25,440\\xa0ft), but appears to be only 6,973\\xa0m (22,877\\xa0ft) to 6,987\\xa0m (22,923\\xa0ft). The summit of Chimborazo, Ecuador's tallest mountain, is usually considered to be the farthest point from the Earth's centre, although the southern summit of Peru's tallest mountain, Huascarán, is another contender.[6] Both have elevations above sea level more than 2\\xa0km (1.2\\xa0mi) less than that of Everest.\\n The bases of mountain islands are below sea level, and given this consideration Mauna Kea (4,207\\xa0m (13,802\\xa0ft) above sea level) is the world's tallest mountain and volcano, rising about 10,203\\xa0m (33,474\\xa0ft) from the Pacific Ocean floor.\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "results = search.invoke(\"biggest moutains in the world\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.kingarthurbaking.com/blog/2021/10/26/best-pancake-tips',\n",
       " 'https://www.bhg.com/scrambled-pancakes-8674832',\n",
       " 'https://www.medicinenet.com/are_pancakes_healthy_or_unhealthy_breakfast_food/article.htm',\n",
       " 'https://www.chefsresource.com/faq/is-pancakes-good-for-breakfast/',\n",
       " 'https://www.tastingtable.com/940660/why-pancakes-taste-better-at-a-diner-than-at-home/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.invoke(query)\n",
    "    return [r['url'] for r in output if type(r)==dict]\n",
    "\n",
    "web_search.invoke(\"Current resources on why pancakes are the best breakfast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_scratchpad', 'input']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       " 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'input_variables': ['agent_scratchpad', 'input'],\n",
       " 'input_types': {'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]],\n",
       "  'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'metadata': {'lc_hub_owner': 'hwchase17',\n",
       "  'lc_hub_repo': 'openai-tools-agent',\n",
       "  'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'},\n",
       " 'tags': None,\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       "  MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       "  MessagesPlaceholder(variable_name='agent_scratchpad')],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build an agent I need to do 2 essential things:\n",
    "\n",
    "1. Connect a model to tools\n",
    "2. Set up a loop in which the model continuously tries to solve the problem by either just calling the llm or calling a tool, observing the result and repeating until finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [web_search]\n",
    "\n",
    "agent = create_tool_calling_agent(llm_chat, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'resources to learn new languages'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://nymag.com/strategist/article/how-to-learn-languages-at-home.html', 'https://www.pcmag.com/picks/the-best-language-learning-software', 'https://www.fluentu.com/blog/learn/free-language-learning-websites/', 'https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1', 'https://www.lifewire.com/best-free-language-learning-websites-1357061']\u001b[0m\u001b[32;1m\u001b[1;3mI found some resources that can help you learn new languages:\n",
      "\n",
      "1. [How to Learn Languages at Home - NYMag](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\n",
      "2. [The Best Language Learning Software - PCMag](https://www.pcmag.com/picks/the-best-language-learning-software)\n",
      "3. [Free Language Learning Websites - FluentU](https://www.fluentu.com/blog/learn/free-language-learning-websites/)\n",
      "4. [Best Online Apps and Courses to Learn New Language - Business Insider](https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1)\n",
      "5. [Best Free Language Learning Websites - Lifewire](https://www.lifewire.com/best-free-language-learning-websites-1357061)\n",
      "\n",
      "You can explore these resources to find the best fit for your language learning journey.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good resources to learn about learning new languages?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'I found some resources that can help you learn new languages:\\n\\n1. [How to Learn Languages at Home - NYMag](https://nymag.com/strategist/article/how-to-learn-languages-at-home.html)\\n2. [The Best Language Learning Software - PCMag](https://www.pcmag.com/picks/the-best-language-learning-software)\\n3. [Free Language Learning Websites - FluentU](https://www.fluentu.com/blog/learn/free-language-learning-websites/)\\n4. [Best Online Apps and Courses to Learn New Language - Business Insider](https://www.businessinsider.com/guides/learning/best-online-apps-courses-to-learn-new-language?op=1)\\n5. [Best Free Language Learning Websites - Lifewire](https://www.lifewire.com/best-free-language-learning-websites-1357061)\\n\\nYou can explore these resources to find the best fit for your language learning journey.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What are good resources to learn about learning new languages?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLearning good programming practices is essential for becoming a successful programmer.\n",
      "Action: web_search\n",
      "Action Input: \"best way to learn good programming practices\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.educative.io/blog/coding-best-practices', 'https://www.freecodecamp.org/news/learn-coding-for-everyone-handbook/', 'https://www.freecodecamp.org/news/how-to-learn-programming/', 'https://careerfoundry.com/en/blog/web-development/ways-to-learn-to-code/']\u001b[0m\u001b[32;1m\u001b[1;3mThere are several resources available online that can help with learning good programming practices.\n",
      "Action: web_search\n",
      "Action Input: \"coding best practices tutorial\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.freecodecamp.org/news/how-to-write-clean-code/', 'https://www.freecodecamp.org/news/clean-coding-for-beginners/', 'https://www.freecodecamp.org/news/learn-coding-for-everyone-handbook/', 'https://realpython.com/tutorials/best-practices/']\u001b[0m\u001b[32;1m\u001b[1;3mI should look for tutorials and guides on coding best practices to learn more.\n",
      "Action: web_search\n",
      "Action Input: \"coding best practices guide\"\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.datacamp.com/tutorial/coding-best-practices-and-guidelines', 'https://www.browserstack.com/guide/coding-standards-best-practices', 'https://www.lambdatest.com/learning-hub/coding-standards', 'https://www.educative.io/blog/coding-best-practices', 'https://www.datacamp.com/blog/python-best-practices-for-better-code']\u001b[0m\u001b[32;1m\u001b[1;3mI have found a variety of tutorials and guides on coding best practices that can help me learn. \n",
      "Final Answer: The best way to learn good programming practices is to explore tutorials and guides available online.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best way to learn good programming practices?',\n",
       " 'agent_scratchpad': [],\n",
       " 'output': 'The best way to learn good programming practices is to explore tutorials and guides available online.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm_chat, tools, prompt)\n",
    "\n",
    "react_agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "react_agent_executor.invoke({\"input\": \"What is the best way to learn good programming practices?\",\n",
    "                             \"agent_scratchpad\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build this same agent but using a more in depth approach going one level down in the abstraction layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's go down the latter of abstraction and build this same agent but leveraging the lower-level capabilities of LangChain's LCEL language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import tool\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    output = search.invoke(query)\n",
    "    return [r['url'] for r in output if type(r)==dict]\n",
    "\n",
    "\n",
    "tools = [web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant.\\\n",
    "            Given a user query you will perform research on the \\\n",
    "                topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bind tools to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have to do is import two last utility functions:\n",
    "- a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, \n",
    "- and a component for converting the output message into an agent action/agent finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.tools import format_to_tool_messages\n",
    "from langchain.agents.output_parsers import ToolsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'open source large language models resources'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://llama.meta.com/llama2/', 'https://llama.meta.com/', 'https://ai.meta.com/blog/meta-llama-3/', 'https://www.datacamp.com/blog/top-open-source-llms', 'https://github.com/Hannibal046/Awesome-LLM']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'best open source large language models 2023'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://huggingface.co/blog/2023-in-llms', 'https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en', 'https://www.shakudo.io/blog/comparing-opensource-large-language-models', 'https://www.lakera.ai/blog/open-source-llms', 'https://github.com/eugeneyan/open-llms']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some valuable resources about open-source large language models (LLMs):\n",
      "\n",
      "1. **Meta's LLaMA (Large Language Model Meta AI)**\n",
      "   - [LLaMA 2](https://llama.meta.com/llama2/)\n",
      "   - [Meta AI Blog on LLaMA](https://ai.meta.com/blog/meta-llama-3/)\n",
      "\n",
      "2. **DataCamp Blog**\n",
      "   - [Top Open-Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\n",
      "\n",
      "3. **GitHub Repositories**\n",
      "   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\n",
      "   - [Open LLMs](https://github.com/eugeneyan/open-llms)\n",
      "\n",
      "4. **Hugging Face Blog**\n",
      "   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\n",
      "\n",
      "5. **CheatSheet.md**\n",
      "   - [LLM Leaderboard](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\n",
      "\n",
      "6. **Shakudo Blog**\n",
      "   - [Comparing Open-Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\n",
      "\n",
      "7. **Lakera Blog**\n",
      "   - [Open-Source LLMs](https://www.lakera.ai/blog/open-source-llms)\n",
      "\n",
      "These resources provide a comprehensive overview of the best open-source LLMs available, their features, and comparisons to help you choose the right model for your needs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='web_search', tool_input={'query': 'open source large language models resources'}, log=\"\\nInvoking: `web_search` with `{'query': 'open source large language models resources'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])], tool_call_id='call_CI0E1IbpFOQW4Im33wjwiGDq')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])]},\n",
       " {'actions': [ToolAgentAction(tool='web_search', tool_input={'query': 'best open source large language models 2023'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source large language models 2023'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])], tool_call_id='call_ltgbCa2tbtah5WScrGD0LxVc')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='web_search', tool_input={'query': 'open source large language models resources'}, log=\"\\nInvoking: `web_search` with `{'query': 'open source large language models resources'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])], tool_call_id='call_CI0E1IbpFOQW4Im33wjwiGDq'), observation=['https://llama.meta.com/llama2/', 'https://llama.meta.com/', 'https://ai.meta.com/blog/meta-llama-3/', 'https://www.datacamp.com/blog/top-open-source-llms', 'https://github.com/Hannibal046/Awesome-LLM'])],\n",
       "  'messages': [FunctionMessage(content='[\"https://llama.meta.com/llama2/\", \"https://llama.meta.com/\", \"https://ai.meta.com/blog/meta-llama-3/\", \"https://www.datacamp.com/blog/top-open-source-llms\", \"https://github.com/Hannibal046/Awesome-LLM\"]', name='web_search')]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='web_search', tool_input={'query': 'best open source large language models 2023'}, log=\"\\nInvoking: `web_search` with `{'query': 'best open source large language models 2023'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'function': {'arguments': '{\"query\": \"open source large language models resources\"}', 'name': 'web_search'}, 'type': 'function'}, {'index': 1, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'function': {'arguments': '{\"query\": \"best open source large language models 2023\"}', 'name': 'web_search'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-2f237d5b-b692-4adc-a232-b68d03c15edd', tool_calls=[{'name': 'web_search', 'args': {'query': 'open source large language models resources'}, 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq'}, {'name': 'web_search', 'args': {'query': 'best open source large language models 2023'}, 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc'}], tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\": \"open source large language models resources\"}', 'id': 'call_CI0E1IbpFOQW4Im33wjwiGDq', 'index': 0}, {'name': 'web_search', 'args': '{\"query\": \"best open source large language models 2023\"}', 'id': 'call_ltgbCa2tbtah5WScrGD0LxVc', 'index': 1}])], tool_call_id='call_ltgbCa2tbtah5WScrGD0LxVc'), observation=['https://huggingface.co/blog/2023-in-llms', 'https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en', 'https://www.shakudo.io/blog/comparing-opensource-large-language-models', 'https://www.lakera.ai/blog/open-source-llms', 'https://github.com/eugeneyan/open-llms'])],\n",
       "  'messages': [FunctionMessage(content='[\"https://huggingface.co/blog/2023-in-llms\", \"https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en\", \"https://www.shakudo.io/blog/comparing-opensource-large-language-models\", \"https://www.lakera.ai/blog/open-source-llms\", \"https://github.com/eugeneyan/open-llms\"]', name='web_search')]},\n",
       " {'output': \"Here are some valuable resources about open-source large language models (LLMs):\\n\\n1. **Meta's LLaMA (Large Language Model Meta AI)**\\n   - [LLaMA 2](https://llama.meta.com/llama2/)\\n   - [Meta AI Blog on LLaMA](https://ai.meta.com/blog/meta-llama-3/)\\n\\n2. **DataCamp Blog**\\n   - [Top Open-Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\\n\\n3. **GitHub Repositories**\\n   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\\n   - [Open LLMs](https://github.com/eugeneyan/open-llms)\\n\\n4. **Hugging Face Blog**\\n   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\\n\\n5. **CheatSheet.md**\\n   - [LLM Leaderboard](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\\n\\n6. **Shakudo Blog**\\n   - [Comparing Open-Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\\n\\n7. **Lakera Blog**\\n   - [Open-Source LLMs](https://www.lakera.ai/blog/open-source-llms)\\n\\nThese resources provide a comprehensive overview of the best open-source LLMs available, their features, and comparisons to help you choose the right model for your needs.\",\n",
       "  'messages': [AIMessage(content=\"Here are some valuable resources about open-source large language models (LLMs):\\n\\n1. **Meta's LLaMA (Large Language Model Meta AI)**\\n   - [LLaMA 2](https://llama.meta.com/llama2/)\\n   - [Meta AI Blog on LLaMA](https://ai.meta.com/blog/meta-llama-3/)\\n\\n2. **DataCamp Blog**\\n   - [Top Open-Source LLMs](https://www.datacamp.com/blog/top-open-source-llms)\\n\\n3. **GitHub Repositories**\\n   - [Awesome LLM](https://github.com/Hannibal046/Awesome-LLM)\\n   - [Open LLMs](https://github.com/eugeneyan/open-llms)\\n\\n4. **Hugging Face Blog**\\n   - [2023 in LLMs](https://huggingface.co/blog/2023-in-llms)\\n\\n5. **CheatSheet.md**\\n   - [LLM Leaderboard](https://cheatsheet.md/llm-leaderboard/best-open-source-llm.en)\\n\\n6. **Shakudo Blog**\\n   - [Comparing Open-Source Large Language Models](https://www.shakudo.io/blog/comparing-opensource-large-language-models)\\n\\n7. **Lakera Blog**\\n   - [Open-Source LLMs](https://www.lakera.ai/blog/open-source-llms)\\n\\nThese resources provide a comprehensive overview of the best open-source LLMs available, their features, and comparisons to help you choose the right model for your needs.\")]}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"What are some good resources about open source large language models?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we want the agent to actually read the links and return a research report rather than just the urls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_text(url: str):\n",
    "    \"\"\"Scrapes the text from a given URL and returns it.\"\"\"\n",
    "    # Send a GET request to the webpage\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the content of the request with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract all text from the webpage\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "            # Print the extracted text\n",
    "            return page_text[:10000]\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [web_search, scrape_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm_chat.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"You are a powerful research assistant. Given a user query you will perform research on the topic using the tools available.\"\n",
    "        ),\n",
    "        (\"user\", \"Scrape and summarize the contents from these urls: {input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"], \n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'How to build a simple research agent using langchain in Python?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://python.langchain.com/v0.2/docs/tutorials/agents/', 'https://build5nines.com/introduction-to-building-ai-agents-with-langchain-and-python/', 'https://towardsdatascience.com/building-a-simple-agent-with-tools-and-toolkits-in-langchain-77e0f9bd1fa5', 'https://dev.to/timesurgelabs/how-to-make-an-ai-agent-in-10-minutes-with-langchain-3i2n', 'https://analyzingalpha.com/langchain-python-tutorial']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://python.langchain.com/v0.2/docs/tutorials/agents/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mBuild an Agent | 🦜️🔗 LangChain Skip to main content LangChain 0.2 is out! Leave feedback on the v0.2 docs here . You can view the v0.1 docs here . Integrations API Reference More People Contributing Templates Cookbooks 3rd party tutorials YouTube arXiv v0.2 v0.2 v0.1 🦜️🔗 LangSmith LangSmith Docs Templates GitHub Templates Hub LangChain Hub JS/TS Docs 💬 Search Introduction Tutorials Build a Question Answering application over a Graph Database Tutorials Build a Simple LLM Application with LCEL Build a Query Analysis System Build a Chatbot Conversational RAG Build an Extraction Chain Build an Agent Tagging data_generation Build a Local RAG Application Build a PDF ingestion and Question/Answering system Build a Retrieval Augmented Generation (RAG) App Vector stores and retrievers Build a Question/Answering system over SQL data Summarize Text How-to guides How-to guides How to use tools in a chain How to use a vectorstore as a retriever How to add memory to chatbots How to use example selectors How to map values to a graph database How to add a semantic layer over graph database How to invoke runnables in parallel How to stream chat model responses How to add default invocation args to a Runnable How to add retrieval to chatbots How to use few shot examples in chat models How to do tool/function calling How to best prompt for Graph-RAG How to install LangChain packages How to add examples to the prompt for query analysis How to use few shot examples How to run custom functions How to use output parsers to parse an LLM response into structured format How to handle cases where no queries are generated How to route between sub-chains How to return structured data from a model How to use toolkits How to add ad-hoc tool calling capability to LLMs and Chat Models Build an Agent with AgentExecutor (Legacy) How to construct knowledge graphs How to partially format prompt templates How to handle multiple queries when doing query analysis How to use built-in tools and toolkits How to pass through arguments from one step to the next How to compose prompts together How to handle multiple retrievers when doing query analysis How to add values to a chain's state How to construct filters for query analysis How to configure runtime chain internals How deal with high cardinality categoricals when doing query analysis Custom Document Loader How to split by HTML header How to split by HTML sections How to use the MultiQueryRetriever How to add scores to retriever results Caching How to use callbacks in async environments How to attach callbacks to a runnable How to propagate callbacks  constructor How to dispatch custom callback events How to pass callbacks in at runtime How to split by character How to cache chat model responses How to init any model in one line How to track token usage in ChatModels How to add tools to chatbots How to split code How to do retrieval with contextual compression How to convert Runnables as Tools How to create custom callback handlers How to create a custom chat model class How to create a custom LLM class Custom Retriever How to create tools How to debug your LLM apps How to load CSVs How to load documents from a directory How to load HTML How to load JSON How to load Markdown How to load Microsoft Office files How to load PDFs How to create a dynamic (self-constructing) chain Text embedding models How to combine results from multiple retrievers How to select examples by length How to select examples by maximal marginal relevance (MMR) How to select examples by n-gram overlap How to select examples by similarity How to use reference examples when doing extraction How to handle long text when doing extraction How to use prompting alone (no tool calling) to do extraction How to add fallbacks to a runnable How to filter messages Hybrid Search How to use the LangChain indexing API How to inspect runnables LangChain Expression Language Cheatsheet How to cache LLM responses How to track token usage for LLMs Run LLMs locally How to get log probabilities How to reorder retrieved results to mitigate the \"lost in the middle\" effect How to split Markdown by Headers How to merge consecutive messages of the same type How to add message history How to migrate from legacy LangChain agents to LangGraph How to migrate chains to LCEL How to retrieve using multiple vectors per document How to pass multimodal data directly to models How to use multimodal prompts How to create a custom Output Parser How to use the output-fixing parser How to parse JSON output How to retry when a parsing error occurs How to parse XML output How to parse YAML output How to use the Parent Document Retriever How to use LangChain with different Pydantic versions How to add chat history How to get a RAG application to add citations How to do per-user retrieval How to get your RAG application to return sources How to stream results from your RAG application How to split JSON data How to recursively split text by characters Response metadata How to do \"self-querying\" retrieval How to split text based on semantic similarity How to chain runnables How to save and load LangChain objects How to split text by tokens How to do question answering over CSVs How to deal with large databases when doing SQL question-answering How to better prompt when doing SQL question-answering How to do query validation as part of SQL question-answering How to stream runnables How to stream responses from an LLM How to use a time-weighted vector store retriever How to return artifacts from a tool How to use chat models to call tools How to disable parallel tool calling How to force models to call a tool How to access the RunnableConfig from a tool How to pass tool outputs to chat models How to pass run time values to tools How to stream events from a tool How to stream tool calls How to convert tools to OpenAI Functions How to handle tool errors How to use few-shot prompting with tool calling How to add a human-in-the-loop for tools How to bind model-specific tools How to trim messages How to create and query vector stores Conceptual guide Ecosystem 🦜🛠️ LangSmith 🦜🕸️ LangGraph Versions Overview Release Policy Packages v0.2 LangChain v0.2 astream_events v2 Changes Security Tutorials Build an Agent On this page Build an Agent Prerequisites This guide assumes familiarity with the following concepts: Chat Models Tools Agents By themselves, language models can't take actions - they just output text.\n",
      "A big use case for LangChain is creating agents .\n",
      "Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them.\n",
      "After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. In this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it. End-to-end agent ​ The code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot. In the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this! # Import relevant functionality from langchain_anthropic import ChatAnthropic from langchain_community . tools . tavily_search import TavilySearchResults from langchain_core . messages import HumanMessage from langgraph . checkpoint . sqlite import SqliteSaver from langgraph . prebuilt import create_react_agent # Create the agent memory = SqliteSaver . from_conn_string ( \":memory:\" ) model = ChatAnthropic ( model_name = \"claude-3-sonnet-20240229\" ) search = TavilySearchResults ( max_results = 2 ) tools = [ search ] agent_executor = create_react_agent ( model , tools , checkpointer = memory ) # Use the agent config = { \"configurable\" : { \"thread_id\" : \"abc123\" } } for chunk in agent_executor . stream ( { \"messages\" : [ HumanMessage ( content = \"hi im bob! and i live in sf\" ) ] } , config ) : print ( chunk ) print ( \"----\" ) for chunk in agent_executor . stream ( { \"messages\" : [ HumanMessage ( content = \"whats the weather where I live?\" ) ] } , config ) : print ( chunk ) print ( \"----\" ) API Reference: ChatAnthropic | TavilySearchResults | HumanMessage {'agent': {'messages': [AIMessage(content=\"Hello Bob! Since you didn't ask a specific question, I don't need to use any tools to respond. It's nice to meet you. San Francisco is a wonderful city with lots to see and do. I hope you're enjoying living there. Please let me know if you have any other questions!\", response_metadata={'id': 'msg_01Mmfzfs9m4XMgVzsCZYMWqH', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 271, 'output_tokens': 65}}, id='run-44c57f9c-a637-4888-b7d9-6d985031ae48-0', usage_metadata={'input_tokens': 271, 'output_tokens': 65, 'total_tokens': 336})]}} ---- {'agent': {'messages': [AIMessage(content=[{'text': 'To get current weather information for your location in San Francisco, let me invoke the search tool:', 'type': 'text'}, {'id': 'toolu_01BGEyQaSz3pTq8RwUUHSRoo', 'input': {'query': 'san francisco weather'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], response_metadata={'id': 'msg_013AVSVsRLKYZjduLpJBY4us', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 347, 'output_tokens': 80}}, id='run-de7923b6-5ee2-4ebe-bd95-5aed4933d0e3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'san francisco weather'}, 'id': 'toolu_01BGEyQaSz3pTq8RwUUHSRoo'}], usage_metadata={'input_tokens': 347, 'output_tokens': 80, 'total_tokens': 427})]}} ---- {'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'locati\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://build5nines.com/introduction-to-building-ai-agents-with-langchain-and-python/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mIntroduction To Building AI Agents With LangChain And Python | Build5Nines Newsletter Advertise Tools IPv4 Address CIDR Range Reference and Calculator Byte Conversion Calculator from KB, MB, GB, TB, PB More Cloud DevOps CI / CD Artificial Intelligence Certification Internet of Things Blockchain Community Development Hardware Operating Systems Cloud, DevOps & SRE Guidance Cloud Microsoft Azure Amazon AWS Google Cloud Platform DevOps HashiCorp Terraform Azure Bicep ARM Templates Azure CLI PowerShell CI / CD Azure DevOps GitHub Git AI Microsoft OpenAI Development C# Node.js Python Certification Top DevOps and SRE Certifications Microsoft Certification HashiCorp Certification GitHub Certification Development • Python Introduction to Building AI Agents with LangChain and Python By Chris Pietschmann June 23, 2024  7:07 AM EDT LangChain is a tool for more easily creating AI agents that can autonomously perform tasks. These agents can streamline operations, enhance user experiences, and handle complex processes with minimal human intervention. Building these AI agents can be difficult and this is the reason for why LangChain exists. LangChain is a cutting-edge framework designed to simplify the creation of AI agents. It enables you to leverage Large Language Models (LLMs) like OpenAI’s GPT-4o or GPT-3.5, providing a robust platform for developing versatile and powerful AI agents. Whether you’re looking to automate customer service, perform data analysis, or create interactive chatbots, LangChain offers the tools and functionalities needed to bring your AI projects to life. This article introduces you to the process of building AI agents with LangChain. We’ll walk you through the essential steps from setting up your environment all the way to an introduction of more advanced features. After reading, you’ll have a great understanding of how to use LangChain to build AI agents using Python. Table of Contents Why LangChain? What is an AI Agent? The Components of LangChain Step-by-Step Guide to Building an AI Agent with LangChain and Python Advanced Concepts Types of LangChain Agents Conclusion Why LangChain? The rise of Large Language Models (LLMs) has revolutionized the field of AI, making it possible to create agents that understand and respond to human language with unprecedented accuracy. LangChain harnesses the power of these models, providing a user-friendly framework that abstracts away much of the complexity involved in AI development and building AI agents. This allows developers to focus on defining their agents’ behaviors and functionalities rather than getting bogged down by technical details. Moreover, LangChain supports a variety of tools and integrations, making it a versatile choice for a wide range of applications. From web scraping and data fetching to natural language processing and summarization, LangChain equips you with everything you need to build sophisticated AI agents. What is an AI Agent? AI agents and the term “ Agentic AI ” describes AI systems designed with a high degree of autonomy, interaction capability, and goal-oriented behavior. These AI agents are capable of performing tasks independently, making decisions, and interacting with users or other systems to fulfill specific objectives. Unlike traditional automated systems, AI agents are proactive and adaptable, making them useful for complex tasks like summarizing documents, generating charts, or scheduling meetings. A great example of an AI agent is Microsoft Copilot , which integrates LLMs and other data sources to enhance productivity through autonomous assistance. The Components of LangChain LangChain is a framework designed to streamline the development of AI agents by leveraging the power of large language models (LLMs). To fully grasp how LangChain operates, it’s essential to understand its core components: chat models, tools, and agents. Each of these plays a crucial role in building functional and efficient AI systems. Chat Models Chat models are the backbone of LangChain. They are advanced language models capable of generating human-like text based on given inputs. These models, such as OpenAI’s GPT-3 and GPT-4, are trained on vast amounts of data, enabling them to understand and respond to a wide range of queries. The primary function of chat models in LangChain is to act as the reasoning engine, processing inputs and generating appropriate responses. Language Models as Reasoning Engines : Chat models in LangChain are not just for generating text; they serve as reasoning engines that determine which actions to take based on the given input. This makes them integral to the decision-making process within an AI agent. Multi-Turn Conversations : These models support multi-turn conversations, allowing them to maintain context over several interactions. This is crucial for applications like customer service chatbots, where continuity and context retention are essential for providing coherent and helpful responses. Tools Tools in LangChain are specialized functions or APIs that the agent can use to perform specific tasks. These tasks can range from simple operations like fetching data from a web page to more complex activities like summarizing a document or performing data analysis. Tool Definition and Integration : Tools are defined using Python functions and can be easily integrated into LangChain. For example, a tool might be created to fetch web content, process data, or interact with other APIs. This modularity allows developers to customize the agent’s capabilities according to their needs. Tool Examples : Common tools include web search utilities, web content fetchers, and summarization tools. These tools enhance the agent’s functionality, enabling it to perform a broader range of tasks effectively. Agents Agents are the orchestrators in LangChain. They use the chat models and tools to perform actions and generate outputs based on user inputs. An agent’s primary role is to determine which tool to use and how to apply it to achieve the desired result. Initialization and Execution : Agents are initialized by combining one or more tools with a chat model. They follow a defined logic to decide which actions to take, often using a zero-shot or few-shot learning approach to understand the context and requirements of the task. Agent Types : LangChain supports various types of agents, each suited to different tasks and scenarios. These include: Zero-Shot Agents : Capable of handling tasks without prior examples, relying solely on the input provided. Few-Shot Agents : Use a few examples to better understand the task before performing it. Memory-Enhanced Agents : Incorporate memory to retain context over multiple interactions, improving the coherence and relevance of responses in long conversations. Advanced Features Beyond the basic components, LangChain offers advanced features that enhance the functionality and versatility of AI agents. These include: Plan and Execute : This approach separates the planning and execution phases, allowing for more structured and efficient task handling. It involves using the langchain_experimental package to define and execute plans. Agent Memory : Adding memory capabilities to agents enables them to remember previous interactions, making them more context-aware and capable of maintaining coherent multi-turn conversations. Interoperability : LangChain is designed to work seamlessly with other frameworks and tools, allowing for easy integration and extended functionality. This includes compatibility with LangGraph for more complex workflows and state management. Practical Application To illustrate how these components work together, let’s consider a practical example. Suppose we want to build an agent that can perform web searches and summarize the results. Here’s how LangChain’s components would come into play: Chat Model : The core of the agent, processing user queries and generating responses. Tools : A web search tool to fetch search results and a summarization tool to condense the information. Agent : Combines the chat model with the tools, determining when to use each tool based on the query and generating a summarized output. # Import necessary libraries\n",
      "from langchain.agents import initialize_agent, AgentType\n",
      "from langchain.tools import DuckDuckGoSearchResults, Tool\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.llms.openai import ChatOpenAI\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "# Initialize tools\n",
      "ddg_search = DuckDuckGoSearchResults()\n",
      "web_fetch_tool = Tool.from_function(\n",
      "    func=fetch_web_page,\n",
      "    name=\"WebFetcher\",\n",
      "    description=\"Fetches the content of a web page\"\n",
      ")\n",
      "\n",
      "# Create summarization tool\n",
      "prompt_template = \"Summarize the following content: {content}\"\n",
      "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
      "llm_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\n",
      "summarize_tool = Tool.from_function(\n",
      "    func=llm_chain.run,\n",
      "    name=\"Summarizer\",\n",
      "    description=\"Summarizes a web page\"\n",
      ")\n",
      "\n",
      "# Initialize agent with tools\n",
      "tools = [ddg_search, web_fetch_tool, summarize_tool]\n",
      "agent = initialize_agent(\n",
      "    tools=tools,\n",
      "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
      "    llm=llm,\n",
      "    verbose=True\n",
      ")\n",
      "\n",
      "# Run the agent\n",
      "prompt = \"Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library.\"\n",
      "print(agent.run(prompt)) By understanding these core components and how they interact, you can harness the power of LangChain to build sophisticated AI agents capable of performing a wide range of tasks efficiently. Step-by-Step Guide to Building an AI Agent with LangChain and Python Let’s look at the process of building an AI agent using LangChain and a vector database for Retrieval Augmented Generation (RAG) . This setup will allow the agent to perform complex queries by leveraging the power of vector databases for efficient and accurate information retrieval. Step 1: Setup Environment Before\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://towardsdatascience.com/building-a-simple-agent-with-tools-and-toolkits-in-langchain-77e0f9bd1fa5'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mFailed to retrieve the webpage: Status code 403\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://dev.to/timesurgelabs/how-to-make-an-ai-agent-in-10-minutes-with-langchain-3i2n'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mHow I Made an AI Agent in 10 Minutes with LangChain - DEV Community Skip to content Navigation menu Search Powered by Search Algolia Search Log in Create account DEV Community Close Add reaction Like Unicorn Exploding Head Raised Hands Fire Jump to Comments Save More... Copy link Copy link Copied to Clipboard Share to Twitter Share to LinkedIn Share to Reddit Share to Hacker News Share to Facebook Share to Mastodon Report Abuse Chandler for TimeSurge Labs Posted on Aug 15, 2023 • Updated on Feb 19 How I Made an AI Agent in 10 Minutes with LangChain # ai # chatgpt # python # tutorial LangChain Crash Course (3 Part Series) 1 How To Use LangChain in 10 Minutes 2 How I Made an AI Agent in 10 Minutes with LangChain 3 How I Use Google's Gemini Pro with LangChain LangChain is a powerful library for Python and Javascript/Typescript that allows you to quickly prototype large language model applications. It allows you to chain together LLM tasks (hence the name) and even allows you to run autonomous agents quickly and easily. In this blog post, we'll explore how to create agents and define custom tools that those agents can use. Prerequisites Python 3.9 3.10 and up have some issues with some of LangChain’s modules. An OpenAI API Key Getting Started We’re going to create a Python virtual environment and install the dependencies that way. mkdir myproject cd myproject # or python3, python3.9, etc depending on your setup python -m venv env\n",
      "source env /bin/activate # this will need run every time before using your agent Enter fullscreen mode Exit fullscreen mode Once that is done we can install dependencies. The only ones we need for this tutorial are LangChain and OpenAI. Finally, python-dotenv will be used to load the OpenAI API keys into the environment. pip install langchain openai python-dotenv requests duckduckgo-search Enter fullscreen mode Exit fullscreen mode LangChain is a very large library so that may take a few minutes. While this is downloading, create a new file called .env and paste your API key in. Here is an example: OPENAI_API_KEY = Your - api - key - here Enter fullscreen mode Exit fullscreen mode Once that is complete we can make our first chain! Quick Concepts Agents are a way to run an LLM in a loop in order to complete a task. Agents are defined with the following: Agent Type - This defines how the Agent acts and reacts to certain events and inputs. For this tutorial we will focus on the ReAct Agent Type. LLM - The AI that actually runs your prompts. Tools - These are Python (or JS/TS) functions that your Agent can call to interact with the world outside of itself. These can be as simple or as complex as you want them to be! Many tools make a Toolkit . There are many toolkits already available built-in to LangChain, but for this example we’ll make our own. Agents Agents use a combination of an LLM (or an LLM Chain) as well as a Toolkit in order to perform a predefined series of steps to accomplish a goal. For this example, we’ll create a couple of custom tools as well as LangChain’s provided DuckDuckGo search tool to create a research agent. 1. Importing Necessary Libraries import requests from bs4 import BeautifulSoup from dotenv import load_dotenv from langchain.tools import Tool , DuckDuckGoSearchResults from langchain.prompts import PromptTemplate from langchain.chat_models import ChatOpenAI from langchain.chains import LLMChain from langchain.agents import initialize_agent , AgentType Enter fullscreen mode Exit fullscreen mode Here's a breakdown of the imports: requests : A popular Python library for making HTTP requests. BeautifulSoup : A library for web scraping purposes to pull the data out of HTML and XML files. load_dotenv : A method to load environment variables from a .env file. LangChain specific imports: These are specific to the LangChain framework and are used to define tools, prompts, chat models, chains, and agents. 2. Loading Environment Variables load_dotenv () Enter fullscreen mode Exit fullscreen mode This line loads environment variables from a .env file. This is useful if you have API keys or other sensitive information that you don't want to hard-code into your script. 3. Setting Up the DuckDuckGo Search Tool ddg_search = DuckDuckGoSearchResults () Enter fullscreen mode Exit fullscreen mode This initializes the DuckDuckGo search tool provided by LangChain. It allows you to search the web using DuckDuckGo and retrieve the results. 4. Defining Headers for Web Requests HEADERS = { ' User-Agent ' : ' Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0 ' } Enter fullscreen mode Exit fullscreen mode This sets a user-agent header for our web requests. Some websites might block requests that don't have a user-agent set, thinking they're from bots. 5. Parsing HTML Content def parse_html ( content ) -> str : soup = BeautifulSoup ( content , ' html.parser ' ) text_content_with_links = soup . get_text () return text_content_with_links Enter fullscreen mode Exit fullscreen mode This function takes in HTML content, uses BeautifulSoup to parse it, and then extracts all the text from it. 6. Fetching Web Page Content def fetch_web_page ( url : str ) -> str : response = requests . get ( url , headers = HEADERS ) return parse_html ( response . content ) Enter fullscreen mode Exit fullscreen mode This function fetches the content of a web page using the requests library and then parses the HTML to extract the text. 7. Creating the Web Fetcher Tool web_fetch_tool = Tool . from_function ( func = fetch_web_page , name = \" WebFetcher \" , description = \" Fetches the content of a web page \" ) Enter fullscreen mode Exit fullscreen mode Here, we're creating a new tool using the Tool.from_function method. This tool will use our fetch_web_page function to fetch and parse web pages. 8. Setting Up the Summarizer prompt_template = \" Summarize the following content: {content} \" llm = ChatOpenAI ( model = \" gpt-3.5-turbo-16k \" ) llm_chain = LLMChain ( llm = llm , prompt = PromptTemplate . from_template ( prompt_template ) ) summarize_tool = Tool . from_function ( func = llm_chain . run , name = \" Summarizer \" , description = \" Summarizes a web page \" ) Enter fullscreen mode Exit fullscreen mode This section sets up a summarizer using the ChatOpenAI model from LangChain. We define a prompt template for summarization, create a chain using the model and the prompt, and then define a tool for summarization. We use ChatGPT 3, 5 16k context as most web pages will exceed the 4k context of ChatGPT 3.5. 9. Initializing the Agent tools = [ ddg_search , web_fetch_tool , summarize_tool ] agent = initialize_agent ( tools = tools , agent_type = AgentType . ZERO_SHOT_REACT_DESCRIPTION , llm = llm , verbose = True ) Enter fullscreen mode Exit fullscreen mode Here, we're initializing an agent with the tools we've defined. This agent will be able to search the web, fetch web pages, and summarize them. Notice how we can re-use the LLM from the summarize tool. 10. Running the Agent prompt = \" Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library. \" print ( agent . run ( prompt )) Enter fullscreen mode Exit fullscreen mode Finally, we define a prompt for our agent and run it. The agent will search the web for information about the Python’s Requests Library, fetch the content fetch some of the content, and then summarize it. Experimentation In this section, we'll explore how to modify the code from the blog post draft to use the experimental Plan and Execute agent. The Plan and Execute agent accomplishes an objective by first planning what to do, then executing the sub-tasks. The planning is almost always done by an LLM, while the execution is usually done by a separate agent equipped with tools. First, install the LangChain experimental package. pip install langchain_experimental Enter fullscreen mode Exit fullscreen mode Then you can import the necessary modules from the langchain_experimental.plan_and_execute package: from langchain_experimental.plan_and_execute import PlanAndExecute , load_agent_executor , load_chat_planner Enter fullscreen mode Exit fullscreen mode Load the planner and executor: planner = load_chat_planner ( llm ) executor = load_agent_executor ( llm , tools , verbose = True ) Enter fullscreen mode Exit fullscreen mode Initialize the Plan and Execute agent: agent = PlanAndExecute ( planner = planner , executor = executor , verbose = True ) Enter fullscreen mode Exit fullscreen mode Run the agent with a prompt: result = agent . run ( \" Research how to use the requests library in Python. Use your tools to search and summarize content into a guide on how to use the requests library. \" ) print ( result ) Enter fullscreen mode Exit fullscreen mode In this example, the agent will first plan the steps needed to accomplish the objective, then execute the sub-tasks using the tools provided. The agent will search the web for information about the requests library in Python, fetch the content of the relevant results, and then summarize them into a guide. Note that the Plan and Execute agent is experimental and may not work as expected in all cases. However, it can be a powerful tool for automating complex tasks that require multiple steps and interactions with external tools. Conclusion LangChain is a game-changer for anyone looking to quickly prototype large language model applications. In just a few minutes, we’ve walked through the process of creating agents, defining custom tools, and even experimenting with the experimental Plan and Execute agent to automate complex tasks. The power of LangChain lies in its simplicity and flexibility. Whether you’re a seasoned developer or just starting out, LangChain’s intuitive design allows you to harness the capabilities of large language models like never before. From generating creative content to running autonomous agents, the possibilities are endless. \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://analyzingalpha.com/langchain-python-tutorial'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mLangChain Python Tutorial: The Ultimate Step-by-Step Guide - Analyzing Alpha Skip to content Analyzing Alpha Analyzing Alpha Menu Home About Blog Podcast Recommended Menu Home About Blog Podcast Recommended Programming LangChain Python Tutorial: The Ultimate Step-by-Step Guide By Leo Smigel Updated on October 13, 2023 As a Python programmer, you might be looking to incorporate large language models (LLMs) into your projects – anything from text generators to trading algorithms. That’s where this comprehensive LangChain Python guide comes in, tailored to fit both novices and seasoned coders. Unlike dense official documents or confusing tutorials, I bring a simplified approach to this tutorial, drawing from years of experience in making complex concepts more digestible. With easy-to-follow instructions and lucid examples, I’ll guide you through the intricate world of LangChain, unlocking its immense potential. Don’t delay; start leveraging LangChain to build innovative applications today. What Is LangChain? LangChain is a software development framework that makes it easier to create applications using large language models (LLMs). It’s an open-source tool with a Python and JavaScript codebase. LangChain allows developers to combine LLMs like GPT-4 with external data, opening up possibilities for various applications such as chatbots, code understanding, summarization, and more. LangChain Pros and Cons Pros: Freely available Open source Supports all major LLMs Variety of modules to perform common tasks Cons: Limited support for languages other than Python Some people express security concerns over the handling of sensitive information. LangChain Pricing LangChain framework is a free-to-use open-source framework. To use some of the LangChain-supported large language models, you must subscribe to the developers of these models and obtain API keys. Getting Started with LangChain Getting started with the LangChain framework is straightforward. You can download the LangChain Python package, import one or more of the LangChain modules, and start building Python applications using large language models. Installation You can install the LangChain package via the following pip command. !pip install langchain Alternatively, if you are using the Anaconda distribution of Python, you can install LangChain via the following conda command. !conda install langchain -c conda-forge A Simple Example LangChain simplifies the use of large language models by offering modules that cover different functions. Later on, I’ll provide detailed explanations of each module. In this section, let’s call a large language model for text generation. The general principle for calling different modules remains consistent throughout. You must perform the following steps to call a Large Language Model (LLM) via LangChain in Python. Step 1: Install Python Package For instance, for OpenAI LLMs, you need to install the OpenAI library. !pip install openai Step 2: Get API Key Get an API key for the corresponding large language module. You can access some LLMs without an API key. The following script imports OpenAI API key from the environment variables. import os\n",
      "api_key = os.getenv('OpenAI_KEY') Step 3: Import LLM Model Import an LLM model from LangChain. For example, we import the OpenAI model in the following script. Sometimes, you need to initialize an LLM model using its API key. from langchain.llms import OpenAI\n",
      "llm = OpenAI(openai_api_key = api_key, temperature=0.9) Step 4: Pass Prompt Pass the prompt to the LLM object you just created. prompt = \"Suggest me a good name for an ice cream parlour that is located on a beach!\"\n",
      "print(llm(prompt)) And that’s it. You can see how simple it is to call an LLM with LangChain. You can replace OpenAI with other LangChain-supported large language models . Let’s now see what other functionalities you can achieve with LangChain modules. LangChain Modules LangChain groups its functionalities into modules enlisted below: Models Prompts Chains Agents Memory Document Loaders and Indexes Models LangChain supports three types of models: Large Language Models Chat Models Text Embedding Models Large Language Models Large language models (LLMs) are the simplest of LangChain models and are the backbone of many other LangChain modules. An LLM takes user inputs as texts and outputs a response as text. LangChain supports a large number of LLMs . We will see a couple of examples in this section. OpenAI Example I have already explained in the basic example section how to use OpenAI LLM. If you want to learn more about directly accessing OpenAI functionalities , check out our OpenAI Python Tutorial. Let’s dig a little further into using OpenAI in LangChain. You can pass an OpenAI model name to the OpenAI model from the langchain.llms module. In the following example, we pass the text-davinci-003 model, which is also the default model. from langchain.llms import OpenAI\n",
      "\n",
      "llm = OpenAI(openai_api_key = api_key,\n",
      "             model_name=\"text-davinci-003\")\n",
      "\n",
      "print(llm(\"Can you tell me a riddle about water?\")) You can pass multiple text prompts to an OpenAI model via the generate() method. For example, the following script returns two outputs, one for each prompt. llm_result = llm.generate([\"Write a poem about hills\", \"Tell me a riddle about oranges\"])\n",
      "len(llm_result.generations) You can access the first output using the generations[0][0].text code. print(llm_result.generations[0][0].text) Likewise, generations[1][0].text returns the second output. print(llm_result.generations[1][0].text) C Transformers Example C transformers package implements various LLMs that you can use in LangChain. You do not need an API key to access C transformers LLMs. To use the C transformers language models in LangChain, you must import the CTransformers model and pass the model name to the model attribute. You can then generate text using CTransformers LLM. from langchain.llms import CTransformers\n",
      "\n",
      "llm = CTransformers(model='marella/gpt-2-ggml')\n",
      "print(llm(\"I am flying to Lisbon on\")) Chat Models LangChain chat models use LLMs at the backend. However, they allow conversational interaction with users. Generating a Single Response To create a chat model, import one of the LangChain-supported chat models , from the langchain.chat_models module. In the following example, we import the ChatOpenAI model, which uses OpenAI LLM at the backend. You also need to import HumanMessage and SystemMessage objects from the langchain.schema module. The former allows you to specify human/user input, while the latter helps you define the system’s/chat bots role. Next, you must create an object of the ChatOpenAI model and pass it your API key. I set the temperature to 0 in the following script since I want the best response. Increasing the temperature will allow the model to generate more creative responses. from langchain.chat_models import ChatOpenAIfrom langchain.schema import (    HumanMessage,    SystemMessage)\n",
      "\n",
      "chat = ChatOpenAI(openai_api_key = api_key, \n",
      "                  temperature=0) To create a human or a system message, you need to pass the message text to the content attribute of the HumanMesssage and SystemMessage objects, respectively. You must pass messages in a list to the chat model. It is not mandatory to pass system messages. We pass a single human message to the OpenAI chat model in the following script. human_message = \"Translate from English to Frech: I love playing Tennis\"\n",
      "chat([HumanMessage(content = human_message)]) Though you can pass anything to the system messages, you will primarily use it to define the system role. Here’s an example. messages = [\n",
      "    SystemMessage(content=\"You are a football historian.\"),\n",
      "    HumanMessage(content=\" Who won the player of the tournament in the 11th Fifa World Cup?\")\n",
      "]\n",
      "chat(messages) Generating Batch Responses You can generate batch responses from chat models. To do so, you must pass a list containing human and system messages. batch_messages = [\n",
      "    [\n",
      "        SystemMessage(content=\"You are a football historian.\"),\n",
      "        HumanMessage(content=\" Who won the player of the tournament in the 11th Fifa World Cup?\")\n",
      "    ],\n",
      "    [\n",
      "        SystemMessage(content=\"You are a Pizza chef.\"),\n",
      "        HumanMessage(content=\"Give me the 7-step recipe to prepare a pizza.\")\n",
      "    ],\n",
      "]\n",
      "result = chat.generate(batch_messages) As with language models, you can access multiple responses using generations list. For instance, you can access the first response via the following script. print(result.generations[0][0].text) The following script prints the second response. print(result.generations[1][0].text) Text Embedding Models The LangChain text embedding models return numeric representations of text inputs that you can use to train statistical algorithms such as machine learning models. You have to import an embedding model from the langchain.embeddings module and pass the input text to the embed_query() method. The following script uses the OpenAIEmbeddings model to generate text embeddings. The output will be a 1536-dimensional vector. from langchain.embeddings import OpenAIEmbeddings\n",
      "\n",
      "embeddings = OpenAIEmbeddings(openai_api_key = api_key)\n",
      "\n",
      "text = \"Paris the capital of france and is famous for its wines and perfumes\"\n",
      "embeddings_result = embeddings.embed_query(text)\n",
      "\n",
      "print(len(embeddings_result)) You can pass multiple text inputs in a list to embed_documents() method, which returns embeddings for all the text inputs. For example, the following script returns embeddings for three text inputs. text = [\"Paris the capital of france and is famous for its wines and perfumes\",\n",
      "        \"London is the Capital of England\",\n",
      "        \"Tokyo is the Capital of Japan\"\n",
      "       ]\n",
      "\n",
      "embeddings_result = embeddings.embed_documents(text)\n",
      "\n",
      "print(\"Total Embeddings:\", len(embeddings_result)) In the next section, I will show you how to replace your hard-coded input templates with something more generic using the LangChain prompts module. Prompts Prompts refer to model inpu\u001b[0m\u001b[32;1m\u001b[1;3mHere are the summaries of the contents from the URLs on how to build a simple research agent using LangChain in Python:\n",
      "\n",
      "1. **LangChain Documentation: Build an Agent**\n",
      "   - **Overview**: This guide provides a comprehensive tutorial on building an agent using LangChain. It covers the prerequisites, including familiarity with chat models, tools, and agents.\n",
      "   - **Key Components**:\n",
      "     - **Chat Models**: Used as reasoning engines to determine actions.\n",
      "     - **Tools**: Specialized functions or APIs for specific tasks.\n",
      "     - **Agents**: Systems that use LLMs to decide which tools to use and how to apply them.\n",
      "   - **Example**: The tutorial includes a code snippet for creating an agent that interacts with a search engine, demonstrating how to set up the agent, integrate tools, and use conversational memory.\n",
      "   - **Steps**:\n",
      "     1. Import necessary functionalities.\n",
      "     2. Create the agent with memory and tools.\n",
      "     3. Use the agent to interact with a search tool and handle multi-turn conversations.\n",
      "\n",
      "2. **Build5Nines: Introduction to Building AI Agents with LangChain and Python**\n",
      "   - **Overview**: This article introduces LangChain as a framework for creating AI agents that can autonomously perform tasks.\n",
      "   - **Key Components**:\n",
      "     - **Chat Models**: Backbone of LangChain, acting as reasoning engines.\n",
      "     - **Tools**: Functions or APIs for specific tasks, enhancing the agent's capabilities.\n",
      "     - **Agents**: Orchestrators that use chat models and tools to perform actions.\n",
      "   - **Example**: The article provides a step-by-step guide to building an AI agent, including setting up the environment, initializing tools, and creating an agent to perform web searches and summarizations.\n",
      "   - **Advanced Features**: Discusses plan and execute approaches, agent memory, and interoperability with other frameworks.\n",
      "\n",
      "3. **Towards Data Science: Building a Simple Agent with Tools and Toolkits in LangChain**\n",
      "   - **Overview**: This tutorial focuses on creating agents and defining custom tools using LangChain.\n",
      "   - **Key Components**:\n",
      "     - **Agents**: Defined with agent types, LLMs, and tools.\n",
      "     - **Tools**: Custom tools created using Python functions.\n",
      "   - **Example**: The tutorial walks through creating a research agent using DuckDuckGo search tool, web fetcher tool, and summarizer tool.\n",
      "   - **Steps**:\n",
      "     1. Import necessary libraries.\n",
      "     2. Load environment variables.\n",
      "     3. Set up search and web fetcher tools.\n",
      "     4. Create a summarizer tool.\n",
      "     5. Initialize and run the agent with a prompt.\n",
      "\n",
      "4. **DEV Community: How I Made an AI Agent in 10 Minutes with LangChain**\n",
      "   - **Overview**: This blog post demonstrates how to quickly create an AI agent using LangChain.\n",
      "   - **Key Components**:\n",
      "     - **Agents**: Use LLMs and toolkits to perform tasks.\n",
      "     - **Tools**: Custom tools and built-in tools in LangChain.\n",
      "   - **Example**: The post provides a quick guide to setting up a Python environment, installing dependencies, and creating an agent with custom tools for web search and summarization.\n",
      "   - **Steps**:\n",
      "     1. Set up a Python virtual environment.\n",
      "     2. Install LangChain and dependencies.\n",
      "     3. Create custom tools and initialize the agent.\n",
      "     4. Run the agent with a specific prompt.\n",
      "\n",
      "5. **Analyzing Alpha: LangChain Python Tutorial**\n",
      "   - **Overview**: This tutorial offers a detailed guide to using LangChain for various applications, including chatbots and summarization.\n",
      "   - **Key Components**:\n",
      "     - **Models**: Large language models, chat models, and text embedding models.\n",
      "     - **Prompts**: Templates for model inputs.\n",
      "     - **Chains and Agents**: Combining models and tools to create functional agents.\n",
      "   - **Example**: The tutorial includes examples of using OpenAI models, creating chat models, and generating text embeddings.\n",
      "   - **Steps**:\n",
      "     1. Install LangChain and necessary libraries.\n",
      "     2. Set up API keys and import models.\n",
      "     3. Create and use chat models and embedding models.\n",
      "     4. Define prompts and initialize agents.\n",
      "\n",
      "These summaries provide a comprehensive overview of the steps and components involved in building a simple research agent using LangChain in Python.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How to build a simple research agent using langchain in Python?',\n",
       " 'output': \"Here are the summaries of the contents from the URLs on how to build a simple research agent using LangChain in Python:\\n\\n1. **LangChain Documentation: Build an Agent**\\n   - **Overview**: This guide provides a comprehensive tutorial on building an agent using LangChain. It covers the prerequisites, including familiarity with chat models, tools, and agents.\\n   - **Key Components**:\\n     - **Chat Models**: Used as reasoning engines to determine actions.\\n     - **Tools**: Specialized functions or APIs for specific tasks.\\n     - **Agents**: Systems that use LLMs to decide which tools to use and how to apply them.\\n   - **Example**: The tutorial includes a code snippet for creating an agent that interacts with a search engine, demonstrating how to set up the agent, integrate tools, and use conversational memory.\\n   - **Steps**:\\n     1. Import necessary functionalities.\\n     2. Create the agent with memory and tools.\\n     3. Use the agent to interact with a search tool and handle multi-turn conversations.\\n\\n2. **Build5Nines: Introduction to Building AI Agents with LangChain and Python**\\n   - **Overview**: This article introduces LangChain as a framework for creating AI agents that can autonomously perform tasks.\\n   - **Key Components**:\\n     - **Chat Models**: Backbone of LangChain, acting as reasoning engines.\\n     - **Tools**: Functions or APIs for specific tasks, enhancing the agent's capabilities.\\n     - **Agents**: Orchestrators that use chat models and tools to perform actions.\\n   - **Example**: The article provides a step-by-step guide to building an AI agent, including setting up the environment, initializing tools, and creating an agent to perform web searches and summarizations.\\n   - **Advanced Features**: Discusses plan and execute approaches, agent memory, and interoperability with other frameworks.\\n\\n3. **Towards Data Science: Building a Simple Agent with Tools and Toolkits in LangChain**\\n   - **Overview**: This tutorial focuses on creating agents and defining custom tools using LangChain.\\n   - **Key Components**:\\n     - **Agents**: Defined with agent types, LLMs, and tools.\\n     - **Tools**: Custom tools created using Python functions.\\n   - **Example**: The tutorial walks through creating a research agent using DuckDuckGo search tool, web fetcher tool, and summarizer tool.\\n   - **Steps**:\\n     1. Import necessary libraries.\\n     2. Load environment variables.\\n     3. Set up search and web fetcher tools.\\n     4. Create a summarizer tool.\\n     5. Initialize and run the agent with a prompt.\\n\\n4. **DEV Community: How I Made an AI Agent in 10 Minutes with LangChain**\\n   - **Overview**: This blog post demonstrates how to quickly create an AI agent using LangChain.\\n   - **Key Components**:\\n     - **Agents**: Use LLMs and toolkits to perform tasks.\\n     - **Tools**: Custom tools and built-in tools in LangChain.\\n   - **Example**: The post provides a quick guide to setting up a Python environment, installing dependencies, and creating an agent with custom tools for web search and summarization.\\n   - **Steps**:\\n     1. Set up a Python virtual environment.\\n     2. Install LangChain and dependencies.\\n     3. Create custom tools and initialize the agent.\\n     4. Run the agent with a specific prompt.\\n\\n5. **Analyzing Alpha: LangChain Python Tutorial**\\n   - **Overview**: This tutorial offers a detailed guide to using LangChain for various applications, including chatbots and summarization.\\n   - **Key Components**:\\n     - **Models**: Large language models, chat models, and text embedding models.\\n     - **Prompts**: Templates for model inputs.\\n     - **Chains and Agents**: Combining models and tools to create functional agents.\\n   - **Example**: The tutorial includes examples of using OpenAI models, creating chat models, and generating text embeddings.\\n   - **Steps**:\\n     1. Install LangChain and necessary libraries.\\n     2. Set up API keys and import models.\\n     3. Create and use chat models and embedding models.\\n     4. Define prompts and initialize agents.\\n\\nThese summaries provide a comprehensive overview of the steps and components involved in building a simple research agent using LangChain in Python.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"How to build a simple research agent using langchain in Python?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encounter a few issues when we try to just add the scrape function to the agent without any other consideration. \n",
    "How about we make this better by improving the inner chain of the agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'LangChain framework learning resources'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702', 'https://python.langchain.com/v0.2/docs/introduction/', 'https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-️-5e751622edb7', 'https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8', 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `web_search` with `{'query': 'LangChain framework tutorials'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://python.langchain.com/v0.2/docs/introduction/', 'https://python.langchain.com/v0.2/docs/tutorials/', 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/', 'https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain', 'https://www.baeldung.com/java-langchain-basics']\u001b[0m\u001b[32;1m\u001b[1;3mHere are some good resources for learning about the LangChain framework:\n",
      "\n",
      "### Articles and Guides\n",
      "1. [Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)\n",
      "2. [Introducing LangChain: A Beginner's Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-\\ufe0f-5e751622edb7)\n",
      "3. [Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)\n",
      "4. [Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)\n",
      "\n",
      "### Official Documentation\n",
      "1. [LangChain Introduction](https://python.langchain.com/v0.2/docs/introduction/)\n",
      "2. [LangChain Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\n",
      "\n",
      "### Tutorials\n",
      "1. [How to Build LLM Applications with LangChain](https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain)\n",
      "2. [LangChain Basics](https://www.baeldung.com/java-langchain-basics)\n",
      "\n",
      "These resources should provide a comprehensive overview and help you get started with the LangChain framework.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "input1 = \"What are good resources on learning about the langchain framework?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good resources on learning about the langchain framework?',\n",
       " 'chat_history': [HumanMessage(content='What are good resources on learning about the langchain framework?'),\n",
       "  AIMessage(content=\"Here are some good resources for learning about the LangChain framework:\\n\\n### Articles and Guides\\n1. [Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)\\n2. [Introducing LangChain: A Beginner's Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-\\\\ufe0f-5e751622edb7)\\n3. [Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)\\n4. [Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)\\n\\n### Official Documentation\\n1. [LangChain Introduction](https://python.langchain.com/v0.2/docs/introduction/)\\n2. [LangChain Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\\n\\n### Tutorials\\n1. [How to Build LLM Applications with LangChain](https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain)\\n2. [LangChain Basics](https://www.baeldung.com/java-langchain-basics)\\n\\nThese resources should provide a comprehensive overview and help you get started with the LangChain framework.\")],\n",
       " 'output': \"Here are some good resources for learning about the LangChain framework:\\n\\n### Articles and Guides\\n1. [Top 5 Resources to Learn LangChain](https://medium.com/@ankity09/top-5-resources-to-learn-langchain-e2bdbbd11702)\\n2. [Introducing LangChain: A Beginner's Guide](https://medium.com/@ellen.hoeven/introducing-langchain-a-beginners-guide-\\\\ufe0f-5e751622edb7)\\n3. [Ultimate Guide to Getting Started with LangChain](https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8)\\n4. [Beginner's Guide to LangChain](https://www.freecodecamp.org/news/beginners-guide-to-langchain/)\\n\\n### Official Documentation\\n1. [LangChain Introduction](https://python.langchain.com/v0.2/docs/introduction/)\\n2. [LangChain Tutorials](https://python.langchain.com/v0.2/docs/tutorials/)\\n\\n### Tutorials\\n1. [How to Build LLM Applications with LangChain](https://www.datacamp.com/tutorial/how-to-build-llm-applications-with-langchain)\\n2. [LangChain Basics](https://www.baeldung.com/java-langchain-basics)\\n\\nThese resources should provide a comprehensive overview and help you get started with the LangChain framework.\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
