{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain-openai\n",
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if running locally\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# FILEPATH: /Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly_live_training_agents/notebooks/1.3-intro-agents-with-langchain.ipynb\n",
    "# SET YOUR API KEYS FOR LANGSMITH AND TAVILY TO RUN THIS NOTEBOOK!\n",
    "# langsmith: https://docs.smith.langchain.com/#:~:text=install%20-U%20langsmith-,Create%20an%20API%20key,click%20Create%20API%20Key.,-Setup%20your%20environment\n",
    "# tavily: https://app.tavily.com/sign-in\n",
    "# openai: https://platform.openai.com/docs/quickstart\n",
    "# import os\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"your-api-key\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"your-api-key\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Research and Report Agent\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Setup the LLM\n",
    "2. Define the tool or list of tools\n",
    "3. Set up a prompt template\n",
    "4. Bind the llm with the tools\n",
    "6. Use LCEL to connect the agent with prompt and the LLM binded with tools\n",
    "7. Create the agent loop\n",
    "8. Wrap everything under `AgentExecutor`\n",
    "9. Invoke the agent with some query input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Setup the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e8785592-4c87-46d9-be7d-75949dda0268-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the tool or list of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.the74million.org/article/7-artificial-intelligence-trends-that-could-reshape-education-in-2024/', 'https://www.hurix.com/top-trends-reshaping-the-world-of-education-in/', 'https://www.forbes.com/sites/forbescommunicationscouncil/2024/01/23/how-ai-and-data-will-change-education-in-2024/', 'https://caktus.ai/blog/ai-in-education', 'https://www.weforum.org/agenda/2024/04/future-learning-ai-revolutionizing-education-4-0/', 'https://www2.ed.gov/documents/ai-report/ai-report.pdf', 'https://www.panopto.com/blog/five-ai-trends-that-are-good-news-for-higher-education/', 'https://www.sciencedirect.com/science/article/pii/S1877050918315382', 'https://elearningindustry.com/how-ai-is-impacting-the-way-we-learn-key-trends-and-insights']\n",
      "7 Artificial Intelligence Trends That Could Reshape Education in 2024 – The 74 The 74 America's Education News Source About The 74 Donate 7 Artificial Intelligence Trends That Could Reshape Education in 2024 News Opinion Home Video Analysis Search Donate Search Sections News Opinion Video Analysis Interactive School Staffing Map Series School (In)Security Future of High School Pandemic The Big Picture The 74 Interview Weaving a Stronger Society 4Fams Keeping It 100 Topics Research critical race theory Investigation Surveillance teacher voice ed tech learning loss Politics Texas Solutions Los Angeles Youth mental health COVID Recovery STEM Pandemic Podcasts Class Disrupted The 74 Enterprise LA School Report COVID Warriors Brown v. Board B.A. Breakthrough View All > The 74 About Us Team Supporters Jobs Contact Newsletters Donate to The 74 Code of Ethics Contact Us feedback@the74million.org Follow Us Support the 74 Republish Our Content The 74 Support the 74 Donate Privacy Policy Terms & Conditions Copyright 2024 The 74 Media, Inc Explore EDlection 2024 Hope Rises in Pine Bluff Artificial Intelligence STEM science of reading Support The 74 and stories like this one. Donate Today! Analysis Future of High School Partner Post 7 Artificial Intelligence Trends That Could Reshape Education in 2024 The revolutionary role of AI in education has a major impact on teaching and learning. Here’s what to watch next year. At PSI High in Sanford, Florida, educators are exploring how AI tools can enhance teaching and learning and also prepare students for the AI-dominated workforce. (Chris Chandler) By Edward Montalvo December 12, 2023 Sharpen Up! Sign up for our free newsletter and start your day with in-depth reporting on the latest topics in education. Sign Up Most Popular Artificial Intelligence Was Los Angeles Schools’ $6 Million AI Venture a Disaster Waiting to Happen? School (In)Security L.A. Schools Probe Charges its Hyped, Now-Defunct AI Chatbot Misused Student Data California California Teachers are Using AI to Grade Papers. Who’s Grading the AI? EDlection 2024 Project 2025 Would Cut Ed. Dept., Fulfill GOP K-12 Wish List Under Trump Chronic Absenteeism With Poll Showing 1 in 4 Kids Is Chronically Absent, How 1 District Is Reaching Out Get stories like these delivered straight to your inbox. Sign up for The 74 Newsletter The future of education has never looked more creative and promising. Since making its public debut last year, ChatGPT has profoundly impacted my perspective on generative AI in education. As a writer and former high school English teacher, I experienced an existential crisis watching the chatbot effortlessly generate lesson plans and rubrics — tasks that would have taken me hours to accomplish. Generative AI allows educators to move beyond traditional learning systems and provide a more responsive, personalized learning experience in which students demonstrate mastery, not just passing grades. “The future of AI in education is not just about adopting new technologies; it’s about reshaping our approach to teaching and learning in a way that is as dynamic and diverse as the students we serve,” XQ Institute Senior Advisor Laurence Holt said. He also formerly worked in the education, business and technology sectors. Through AI, we can also transcend the limitations of the Carnegie Unit — a century-old system in which a high school diploma is based on how much time students spend in specific subject classes. Changing that rigid system is our mission at XQ . We work with schools and communities to transform high school learning so it’s more relevant and engaging while also preparing students to succeed in college, career and real life. We recently co-convened a two-day summit with the Emerson Collective, in partnership with MeshEd and Betaworks, to bring educators and innovators together in a collaborative space — envisioning ways to use AI technology for transforming high school redesign. Those ideas and insights are available to explore on this beta wiki page . After a year’s worth of conversations and observations with educators, our AI convening and EdTech Week 2023 , there is much to share with educators to help them make the most of the rapidly evolving ecosystem of artificial intelligence. Here are seven AI in education trends to be aware of next year. 1. Professional Development Throughout 2023, demand for AI professional development for educators remained high. In 2024, we should see an avalanche of districts and schools providing their educators with AI professional development materials to integrate these tools into their teaching practices. At PSI High , an XQ school in Sanford, Florida, MIT’s STEP Lab ’s Sarah Wharton visited to present interesting ways to think about AI in the context of the school. “We looked at ChatGPT as a possible tutor, personal assistant, creative tool and research assistant,” said PSI High School Coordinator Angela Daniel. “In our PD session, we considered how these cool applications could be used in classrooms as learning tools that accelerate learning and teach the tool simultaneously.” Daniel explained that teaching students how to use AI is a first step that will change things for students going forward.“But to really get at the heart of that question, we need to understand how generative AI can change our processes and resources right now,” she added. For the team at PSI, that means learning how to use generative AI effectively with ongoing support as the application continues to evolve. Workshops, online courses and collaborative learning communities are also increasingly popular for providing educators with hands-on experience in AI. Want to stay on top of trends to help you rethink high school? Check out the XQ Xtra, a newsletter for educators that comes out twice a month. Sign up here . 2. Formal AI Policy Integrating AI in classrooms is no longer a matter of “if” but “how,” making it imperative for educators and policymakers to navigate this terrain with informed and responsible strategies. However, the landscape of AI policy development — especially regarding education — has been dynamic, if not lagging. The Council of Europe has continued providing critical insights for equitable policy and practice, an area where U.S. schools have been seeking guidance . New York City Public Schools, after initially banning ChatGPT, is now collaborating with academics, experts and school districts in the AI Policy Lab , focusing on issues such as privacy and cybersecurity. Recently, the Biden administration issued an executive order to guide the U.S. in leveraging artificial intelligence. This directive emphasized AI safety, privacy, equity and responsible use, signaling a shift in how AI is integrated into sectors like education. However, it is likely that AI policy in education will develop on a location-by-location basis first. 3. Open-Source Tool Development Concerns about AI’s ethical implications and biases are sure to shape policy goals. One way to alleviate those pressures is the expansion and increased use of open-sourced tools — programs where the code is accessible and can be modified. The potential for AI to perpetuate biases is significant , however, expect the conversation to focus less on the output of AI tools and more on the kind of data it’s trained on . Ensuring AI tools are equitable and inclusive goes beyond technical challenges — it requires continuous dialogue among educators, technologists and policymakers. This conversation is essential for addressing data privacy, surveillance and ethical use of student data. With a democratized, open-source marketplace, we could see the market promote open-sourced tools as they grow in popularity. 4. Frameworks for Teaching AI Before the start of the 2023-24 academic year, educators and schools were waiting for a framework to guide their integration of AI tools . As policy moves forward in 2024 and more institutions develop professional development materials to train and support educators, expect AI curricula frameworks to finally emerge. Frameworks like TeachAI are being developed to guide the integration of AI in education. These frameworks focus on aligning AI applications with educational goals and promoting equitable access to technology, ensuring that AI complements and enhances student learning experiences. 5. AI Literacy, Competencies and Standards With AI becoming more prevalent in various sectors, including education, there’s a growing need to integrate AI literacy goals and specific learning outcomes into school curricula. This involves teaching students how to use AI tools and understand the basics of AI technology, its applications and its implications. At the Purdue Polytechnic High School network, an XQ partner with three campuses in Indiana , CEO Keeanna Warren explained how equipping staff and students with the knowledge and skills to harness AI’s potential promotes effective and responsible use of AI to enhance learning experiences. “We firmly believe that our students’ innate curiosity drives their desire to learn, and we trust their integrity,” she said. “If AI can be used for cheating, it reflects a flaw in the assessment, not in our students’ character.” The challenge lies in integrating AI literacy into an already packed curriculum. However, the opportunity to foster critical thinking, problem-solving and ethical reasoning skills through AI education is entirely possible. 6. AI-Powered Adaptive Learning Systems One of the more exciting pathways with AI is that student learning experiences will become more uniquely adaptive and personalized with a quicker turnaround. But creating effective programs requires training these systems on some level of student data -– a delicate balance. As policy formalizes how student data gets implemented into these programs, AI-driven adaptive learning systems will emerge to shift instructional practice. Expect these programs to appear prominently in assessments and curriculum packages before evolving into real-time feedback systems that can inform teachers even during a lesson. 7. Custom GPTs Built By Educators While all these advancements are promising and exciting, the marketplace for AI-driven ed tech tools will become incredibly crowded quickly. Recently, OpenAI’s maker space for building and using custom GPTs, which both use and are built by ChatGPT, is guaranteed to be a massive disruptor. Ty Boyland, school-based enterprise coordinator and music production teacher at Crosstown High, designed a custom GPT. ( Crosstown High is another XQ school in Memphis, Tennessee .) Boyland’s students use Dall-E, an AI system for generating images, with GPT-4 to create designs and prints for student-driven projects. “But how do you create a project combining culinary and music production?” Boyland wondered. His customized GPT pairs XQ’s competencies with Tennessee State Standards to build a new project. It will be interesting to see what educators create in this space to resolve pain points teachers and schools are intimately familiar with and what gets made to help schools achieve their vision and mission. The Bottom Line for Educators From policy shifts emphasizing equity and privacy to the emergence of AI-driven curricula, the transformation is palpable. We’ve seen how AI can revolutionize and disrupt classroom practices, empower educators through professional development, and create inclusive, personalized student learning experiences. But the burgeoning AI ed tech market demands discernment. Educators must navigate this space wisely , choosing tools that genuinely enhance learning and align with ethical standards. As we enter 2024, educators and stakeholders face a challenge: keeping pace with AI and engaging with it thoughtfully to catalyze educational excellence instead of just putting a new face on old practices. It’s the primary reason we at XQ convened so many educators and innovators into one space— to rethink high school by harnessing the potential of our AI-powered future. We look forward to sharing more with you in the coming year. Do you want to learn more about how to rethink high school? The XQ Xtra is a newsletter for educators that comes out twice a month. Sign up here . Disclosure: The XQ Institute is a financial supporter of The 74 . Get stories like these delivered straight to your inbox. Sign up for The 74 Newsletter Republish This Article Learn More Edward Montalvo is the senior education writer at The XQ Institute. He was previously Dean of Students at PSI High in Sanford, Florida. AI Artificial Intelligence College to Career ed tech edtech education Education AI Florida future of high school Indiana Indianapolis innovation Memphis Tennessee Republish This Article We want our stories to be shared as widely as possible — for free. Please view The 74's republishing terms. 7 Artificial Intelligence Trends That Could Reshape Education in 2024 The revolutionary role of AI in education has a major impact on teaching and learning. Here’s what to watch next year. By Edward Montalvo This story first appeared at The 74 , a nonprofit news site covering education. Sign up for free newsletters from The 74 to get more like this in your inbox. The future of education has never looked more creative and promising. Since making its public debut last year, ChatGPT has profoundly impacted my perspective on generative AI in education. As a writer and former high school English teacher, I experienced an existential crisis watching the chatbot effortlessly generate lesson plans and rubrics — tasks that would have taken me hours to accomplish. Generative AI allows educators to move beyond traditional learning systems and provide a more responsive, personalized learning experience in which students demonstrate mastery, not just passing grades. “The future of AI in education is not just about adopting new technologies; it’s about reshaping our approach to teaching and learning in a way that is as dynamic and diverse as the students we serve,” XQ Institute Senior Advisor Laurence Holt said. He also formerly worked in the education, business and technology sectors. Through AI, we can also transcend the limitations of the Carnegie Unit — a century-old system in which a high school diploma is based on how much time students spend in specific subject classes. Changing that rigid system is our mission at XQ . We work with schools and communities to transform high school learning so it’s more relevant and engaging while also preparing students to succeed in college, career and real life. We recently co-convened a two-day summit with the Emerson Collective, in partnership with MeshEd and Betaworks, to bring educators and innovators together in a collaborative space — envisioning ways to use AI technology for transforming high school redesign. Those ideas and insights are available to explore on this beta wiki page . After a year’s worth of conversations and observations with educators, our AI convening and EdTech Week 2023 , there is much to share with educators to help them make the most of the rapidly evolving ecosystem of artificial intelligence. Here are seven AI in education trends to be aware of next year. 1. Professional Development Throughout 2023, demand for AI professional development for educators remained high. In 2024, we should see an avalanche of districts and schools providing their educators with AI professional development materials to integrate these tools into their teaching practices. At PSI High , an XQ school in Sanford, Florida, MIT’s STEP Lab ’s Sarah Wharton visited to present interesting ways to think about AI in the context of the school. “We looked at ChatGPT as a possible tutor, personal assistant, creative tool and research assistant,” said PSI High School Coordinator Angela Daniel. “In our PD session, we considered how these cool applications could be used in classrooms as learning tools that accelerate learning and teach the tool simultaneously.” Daniel explained that teaching students how to use AI is a first step that will change things for students going forward.“But to really get at the heart of that question, we need to understand how generative AI can change our processes and resources right now,” she added. For the team at PSI, that means learning how to use generative AI effectively with ongoing support as the application continues to evolve. Workshops, online courses and collaborative learning communities are also increasingly popular for providing educators with hands-on experience in AI. Want to stay on top of trends to help you rethink high school? Check out the XQ Xtra, a newsletter for educators that comes out twice a month. Sign up here . 2. Formal AI Policy Integrating AI in classrooms is no longer a matter of “if” but “how,” making it imperative for educators and policymakers to navigate this terrain with informed and responsible strategies. However, the landscape of AI policy development — especially regarding education — has been dynamic, if not lagging. The Council of Europe has continued providing critical insights for equitable policy and practice, an area where U.S. schools have been seeking guidance . New York City Public Schools, after initially banning ChatGPT, is now collaborating with academics, experts and school districts in the AI Policy Lab , focusing on issues such as privacy and cybersecurity. Recently, the Biden administration issued an executive order to guide the U.S. in leveraging artificial intelligence. This directive emphasized AI safety, privacy, equity and responsible use, signaling a shift in how AI is integrated into sectors like education. However, it is likely that AI policy in education will develop on a location-by-location basis first. 3. Open-Source Tool Development Concerns about AI’s ethical implications and biases are sure to shape policy goals. One way to alleviate those pressures is the expansion and increased use of open-sourced tools — programs where the code is accessible and can be modified. The potential for AI to perpetuate biases is significant , however, expect the conversation to focus less on the output of AI tools and more on the kind of data it’s trained on . Ensuring AI tools are equitable and inclusive goes beyond technical challenges — it requires continuous dialogue among educators, technologists and policymakers. This conversation is essential for addressing data privacy, surveillance and ethical use of student data. With a democratized, open-source marketplace, we could see the market promote open-sourced tools as they grow in popularity. 4. Frameworks for Teaching AI Before the start of the 2023-24 academic year, educators and schools were waiting for a framework to guide their integration of AI tools . As policy moves forward in 2024 and more institutions develop professional development materials to train and support educators, expect AI curricula frameworks to finally emerge. Frameworks like TeachAI are being developed to guide the integration of AI in education. These frameworks focus on aligning AI applications with educational goals and promoting equitable access to technology, ensuring that AI complements and enhances student learning experiences. 5. AI Literacy, Competencies and Standards With AI becoming more prevalent in various sectors, including education, there’s a growing need to integrate AI literacy goals and specific learning outcomes into school curricula. This involves teaching students how to use AI tools and understand the basics of AI technology, its applications and its implications. At the Purdue Polytechnic High School network, an XQ partner with three campuses in Indiana , CEO Keeanna Warren explained how equipping staff and students with the knowledge and skills to harness AI’s potential promotes effective and responsible use of AI to enhance learning experiences. “We firmly believe that our students’ innate curiosity drives their desire to learn, and we trust their integrity,” she said. “If AI can be used for cheating, it reflects a flaw in the assessment, not in our students’ character.” The challenge lies in integrating AI literacy into an already packed curriculum. However, the opportunity to foster critical thinking, problem-solving and ethical reasoning skills through AI education is entirely possible. 6. AI-Powered Adaptive Learning Systems One of the more exciting pathways with AI is that student learning experiences will become more uniquely adaptive and personalized with a quicker turnaround. But creating effective programs requires training these systems on some level of student data -– a delicate balance. As policy formalizes how student data gets implemented into these programs, AI-driven adaptive learning systems will emerge to shift instructional practice. Expect these programs to appear prominently in assessments and curriculum packages before evolving into real-time feedback systems that can inform teachers even during a lesson. 7. Custom GPTs Built By Educators While all these advancements are promising and exciting, the marketplace for AI-driven ed tech tools will become incredibly crowded quickly. Recently, OpenAI’s maker space for building and using custom GPTs, which both use and are built by ChatGPT, is guaranteed to be a massive disruptor. Ty Boyland, school-based enterprise coordinator and music production teacher at Crosstown High, designed a custom GPT. ( Crosstown High is another XQ school in Memphis, Tennessee .) Boyland’s students use Dall-E, an AI system for generating images, with GPT-4 to create designs and prints for student-driven projects. “But how do you create a project combining culinary and music production?” Boyland wondered. His customized GPT pairs XQ’s competencies with Tennessee State Standards to build a new project. It will be interesting to see what educators create in this space to resolve pain points teachers and schools are intimately familiar with and what gets made to help schools achieve their vision and mission. The Bottom Line for Educators From policy shifts emphasizing equity and privacy to the emergence of AI-driven curricula, the transformation is palpable. We’ve seen how AI can revolutionize and disrupt classroom practices, empower educators through professional development, and create inclusive, personalized student learning experiences. But the burgeoning AI ed tech market demands discernment. Educators must navigate this space wisely , choosing tools that genuinely enhance learning and align with ethical standards. As we enter 2024, educators and stakeholders face a challenge: keeping pace with AI and engaging with it thoughtfully to catalyze educational excellence instead of just putting a new face on old practices. It’s the primary reason we at XQ convened so many educators and innovators into one space— to rethink high school by harnessing the potential of our AI-powered future. We look forward to sharing more with you in the coming year. Do you want to learn more about how to rethink high school? The XQ Xtra is a newsletter for educators that comes out twice a month. Sign up here . Disclosure: The XQ Institute is a financial supporter of The 74 . Copy HTML On The 74 Today Sections News Opinion Video Analysis Interactive School Staffing Map Series School (In)Security Future of High School Pandemic The Big Picture The 74 Interview Weaving a Stronger Society 4Fams Keeping It 100 Topics Research critical race theory Investigation Surveillance teacher voice ed tech learning loss Politics Texas Solutions Los Angeles Youth mental health COVID Recovery STEM Pandemic Podcasts Class Disrupted The 74 Enterprise LA School Report COVID Warriors Brown v. Board B.A. Breakthrough View All > The 74 About Us Team Supporters Jobs Contact Newsletters Donate to The 74 Code of Ethics Contact Us feedback@the74million.org Follow Us Support the 74 Republish Our Content The 74 Support the 74 Donate Privacy Policy Terms & Conditions Copyright 2024 The 74 Media, Inc\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Tools: search and scraping an internet page\n",
    "from langchain.tools import tool\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "serpapi_params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"api_key\": os.environ[\"SERPAPI_KEY\"]\n",
    "}\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_tool(query: str):\n",
    "    \"\"\"Searches the web given a user query and returns the most relevant links\"\"\"\n",
    "    search = GoogleSearch({**serpapi_params, \"q\": query, \"n\": 5})\n",
    "    output = search.get_dict()\n",
    "    results = output[\"organic_results\"]\n",
    "    return [r[\"link\"] for r in results]\n",
    "\n",
    "@tool\n",
    "def scrape_text(url: str):\n",
    "    \"\"\"Scrapes text from an internet page\"\"\"\n",
    "    # source: copied from this script by Harrison Chase https://gist.github.com/hwchase17/69a8cdef9b01760c244324339ab64f0c\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        #check\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Extract all the text from the page\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "            \n",
    "            return page_text\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code: {response.status_code}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        # In case of error print the error message\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\"\n",
    "\n",
    "query = \"Trends in using AI for education.\"\n",
    "links = search_tool.invoke(query)\n",
    "print(links)\n",
    "\n",
    "url = links[0]\n",
    "\n",
    "print(scrape_text.invoke(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_final_report(markdown_report: str):\n",
    "    \"\"\"Writes the final report to a file\"\"\"\n",
    "    with open(\"final_report.md\", \"w\") as file:\n",
    "        file.write(markdown_report)\n",
    "    \n",
    "    return markdown_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, scrape_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set up a prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "WRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. \\\n",
    "                        Your sole purpose is to write well written, critically \\\n",
    "                        acclaimed, objective \\\n",
    "                        and structured reports on given text.\"\n",
    "# Report prompts from https://github.com/assafelovic/gpt-researcher/blob/master/gpt_researcher/master/prompts.py\n",
    "RESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n",
    "Write a detailed research report on the following question:\\n\n",
    "\"{input}\". -- \\\n",
    "The report should focus on the answer to the question, should be well structured, informative, \\\n",
    "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
    "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
    "You must write the report with markdown syntax.\n",
    "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
    "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
    "You must write the report in apa format.\n",
    "Please do your best, this is very important to my career.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
    "        (\"placeholder\"), \"{chat_history}\",\n",
    "        (\"human\", RESEARCH_REPORT_TEMPLATE),\n",
    "        (\"placeholder\"), \"{agent_scratchpad}\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bind the llm with the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.tools import format_to_tool_messages\n",
    "from langchain.agents.output_parsers import ToolsAgentOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use LCEL to define and connect agent, prompt and the LLM binded with tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "agent = (\n",
    "RunnablePassthrough.assign(\n",
    "                    agent_scratchpad=lambda x: format_to_tool_messages(x['intermediate_steps'])\n",
    "                    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | ToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create the agent loop\n",
    "\n",
    "7. Wrap everything under `AgentExecutor`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Invoke the agent with some query input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_tool` with `{'query': 'current trends in AI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://www.ibm.com/blog/artificial-intelligence-trends/', 'https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends', 'https://www.eweek.com/artificial-intelligence/ai-trends/', 'https://www.simplilearn.com/artificial-intelligence-ai-and-machine-learning-trends-article', 'https://www.forbes.com/sites/bernardmarr/2023/09/18/the-10-most-important-ai-trends-for-2024-everyone-must-be-ready-for-now/', 'https://www.coursera.org/articles/ai-trends', 'https://www.synthesia.io/post/ai-trends', 'https://sloanreview.mit.edu/article/five-key-trends-in-ai-and-data-science-for-2024/', 'https://appinventiv.com/blog/ai-trends/']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://www.ibm.com/blog/artificial-intelligence-trends/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mThe most important AI trends in 2024 - IBM Blog The most important AI trends in 2024 Artificial intelligence Business transformation February 9, 2024 By Dave Bergmann 12 min read 2022 was the year that generative artificial intelligence (AI) exploded into the public consciousness, and 2023 was the year it began to take root in the business world. 2024 thus stands to be a pivotal year for the future of AI, as researchers and enterprises seek to establish how this evolutionary leap in technology can be most practically integrated into our everyday lives. The evolution of generative AI has mirrored that of computers, albeit on a dramatically accelerated timeline. Massive, centrally operated mainframe computers from a few players gave way to smaller, more efficient machines accessible to enterprises and research institutions. In the decades that followed, incremental advances yielded home computers that hobbyists could tinker with. In time, powerful personal computers with intuitive no-code interfaces became ubiquitous. Generative AI has already reached its “hobbyist” phase—and as with computers, further progress aims to attain greater performance in smaller packages. 2023 saw an explosion of increasingly efficient foundation models with open licenses, beginning with the launch of Meta’s LlaMa family of large language models (LLMs) and followed by the likes of StableLM, Falcon, Mistral, and Llama 2 . DeepFloyd and Stable Diffusion have achieved relative parity with leading proprietary models. Enhanced with fine-tuning techniques and datasets developed by the open source community, many open models can now outperform all but the most powerful closed-source models on most benchmarks, despite far smaller parameter counts. As the pace of progress accelerates, the ever-expanding capabilities of state-of-the-art models will garner the most media attention. But the most impactful developments may be those focused on governance, middleware, training techniques and data pipelines that make generative AI more trustworthy , sustainable and accessible, for enterprises and end users alike. Here are some important current AI trends to look out for in the coming year. Reality check: more realistic expectations Multimodal AI Small(er) language models and open source advancements GPU shortages and cloud costs Model optimization is getting more accessible Customized local models and data pipelines More powerful virtual agents Regulation, copyright and ethical AI concerns Shadow AI (and corporate AI policies) Reality check: more realistic expectations When generative AI first hit mass awareness, a typical business leader’s knowledge came mostly from marketing materials and breathless news coverage. Tangible experience (if any) was limited to messing around with ChatGPT and DALL-E. Now that the dust has settled, the business community now has a more refined understanding of AI-powered solutions. The Gartner Hype Cycle positions Generative AI squarely at “Peak of Inflated Expectations,” on the cusp of a slide into the “Trough of Disillusionment” [1] —in other words, about to enter a (relatively) underwhelming transition period—while Deloitte’s “State of Generated AI in the Enterprise “ report from Q1 2024 indicated that many leaders “expect substantial transformative impacts in the short term.” [2] The reality will likely fall in between: generative AI offers unique opportunities and solutions, but it will not be everything to everyone. How real-world results compare to the hype is partially a matter of perspective. Standalone tools like ChatGPT typically take center stage in the popular imagination, but smooth integration into established services often yields more staying power. Prior to the current hype cycle, generative machine learning tools like the “Smart Compose” feature rolled out by Google in 2018 weren’t heralded as a paradigm shift, despite being harbingers of today’s text generating services. Similarly, many high-impact generative AI tools are being implemented as integrated elements of enterprise environments that enhance and complement, rather than revolutionize or replace, existing tools: for example, “Copilot” features in Microsoft Office, “Generative Fill” features in Adobe Photoshop or virtual agents in productivity and collaboration apps . Where generative AI first builds momentum in everyday workflows will have more influence on the future of AI tools than the hypothetical upside of any specific AI capabilities. According to a recent IBM survey of over 1,000 employees at enterprise-scale companies , the top three factors driving AI adoption were advances in AI tools that make them more accessible, the need to reduce costs and automate key processes and the increasing amount of AI embedded into standard off-the-shelf business applications. Multimodal AI (and video) That being said, the ambition of state-of-the-art generative AI is growing. The next wave of advancements will focus not only on enhancing performance within a specific domain, but on multimodal models that can take multiple types of data as input. While models that operate across different data modalities are not a strictly new phenomenon—text-to-image models like CLIP and speech-to-text models like Wave2Vec have been around for years now—they’ve typically only operated in one direction, and were trained to accomplish a specific task. The incoming generation of interdisciplinary models, comprising proprietary models like OpenAI’s GPT-4V or Google’s Gemini, as well as open source models like LLaVa, Adept or Qwen-VL, can move freely between natural language processing (NLP) and computer vision tasks. New models are also bringing video into the fold: in late January, Google announced Lumiere, a text-to-video diffusion model that can also perform image-to-video tasks or use images for style reference. The most immediate benefit of multimodal AI is more intuitive, versatile AI applications and virtual assistants. Users can, for example, ask about an image and receive a natural language answer, or ask out loud for instructions to repair something and receive visual aids alongside step-by-step text instructions. On a higher level, multimodal AI allows for a model to process more diverse data inputs, enriching and expanding the information available for training and inference. Video, in particular, offers great potential for holistic learning. “There are cameras that are on 24/7 and they’re capturing what happens just as it happens without any filtering, without any intentionality,” says Peter Norvig, Distinguished Education Fellow at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). [3] “AI models haven’t had that kind of data before. Those models will just have a better understanding of everything.” Small(er) language models and open source advancements In domain-specific models—particularly LLMs—we’ve likely reached the point of diminishing returns from larger parameter counts. Sam Altman, CEO of OpenAI (whose GPT-4 model is rumored to have around 1.76 trillion parameters), suggested as much at MIT’s Imagination in Action event last April: “I think we’re at the end of the era where it’s going to be these giant models, and we’ll make them better in other ways,” he predicted. “I think there’s been way too much focus on parameter count.” Massive models jumpstarted this ongoing AI golden age, but they’re not without drawbacks. Only the very largest companies have the funds and server space to train and maintain energy-hungry models with hundreds of billions of parameters. According to one estimate from the University of Washington, training a single GPT-3-sized model requires the yearly electricity consumption of over 1,000 households; a standard day of ChatGPT queries rivals the daily energy consumption of 33,000 U.S. households. [4] Smaller models, meanwhile, are far less resource-intensive. An influential March 2022 paper from Deepmind demonstrated that training smaller models on more data yields better performance than training larger models on fewer data. Much of the ongoing innovation in LLMs has thus focused on yielding greater output from fewer parameters. As demonstrated by recent progress of models in the 3–70 billion parameter range, particularly those built upon LLaMa, Llama 2 and Mistral foundation models in 2023, models can be downsized without much performance sacrifice. The power of open models will continue to grow. In December of 2023, Mistral released “Mixtral,” a mixture of experts (MoE) model integrating 8 neural networks, each with 7 billion parameters. Mistral claims that Mixtral not only outperforms the 70B parameter variant of Llama 2 on most benchmarks at 6 times faster inference speeds, but that it even matches or outperforms OpenAI’s far larger GPT-3.5 on most standard benchmarks. Shortly thereafter, Meta announced in January that it has already begun training of Llama 3 models, and confirmed that they will be open sourced. Though details (like model size) have not been confirmed, it’s reasonable to expect Llama 3 to follow the framework established in the two generations prior. These advances in smaller models have three important benefits: They help democratize AI: smaller models that can be run at lower cost on more attainable hardware empower more amateurs and institutions to study, train and improve existing models. They can be run locally on smaller devices: this allows more sophisticated AI in scenarios like edge computing and the internet of things (IoT). Furthermore, running models locally—like on a user’s smartphone—helps to sidestep many privacy and cybersecurity concerns that arise from interaction with sensitive personal or proprietary data. They make AI more explainable: the larger the model, the more difficult it is to pinpoint how and where it makes important decisions. Explainable AI is essential to understanding, improving and trusting the output of AI systems. GPU shortages and cloud costs The trend toward smaller models will be driven as much by necessity as by entrepreneurial vigor, as cloud computing costs increase as the availability of hardware decrease. “The big companies (and more of them) are all trying to bring AI capabilities in-house, and there is a bit of a run on GPUs,” says James Landay, Vice-Director and Faculty Director of Research, Stanford HAI. “This will create a huge pressure not only for increased GPU production, but for innovators to come up with hardware solutions that are cheaper and easier to make and use.” 1 As a late 2023 O’Reilly report explains, cloud providers currently bear much of the computing burden: relatively few AI adopters maintain their own infrastructure, and hardware shortages will only elevate the hurdles and costs of setting up on-premise servers. In the long term, this may put upward pressure on cloud costs as providers update and optimize their own infrastructure to effectively meet demand from generative AI. [5] For enterprises, navigating this uncertain landscape requires flexibility, in terms of both models–leaning on smaller, more efficient models where necessary or larger, more performant models when practical–and deployment environment. “We don’t want to constrain where people deploy [a model],” said IBM CEO Arvind Krishna in a December 2023 interview with CNBC , in reference to IBM’s watsonx platform. “So [if] they want to deploy it on a large public cloud, we’ll do it there. If they want to deploy it at IBM, we’ll do it at IBM. If they want to do it on their own, and they happen to have enough infrastructure, we’ll do it there.” Model optimization is getting more accessible The trend towards maximizing the performance of more compact models is well served by the recent output of the open source community. Many key advancements have been (and will continue to be) driven not just by new foundation models, but by new techniques and resources (like open source datasets) for training, tweaking, fine-tuning or aligning pre-trained models. Notable model-agnostic techniques that took hold in 2023 include: Low Rank Adaptation (LoRA): Rather than directly fine-tuning billions of model parameters, LoRA entails freezing pre-trained model weights and injecting trainable layers—which represent the matrix of changes to model weights as 2 smaller ( lower rank ) matrices—in each transformer block. This dramatically reduces the number of parameters that need to be updated, which, in turn, dramatically speeds up fine-tuning and reduces memory needed to store model updates. Quantization: Like lowering the bitrate of audio or video to reduce file size and latency, quantization lowers the precision used to represent model data points—for example, from 16-bit floating point to 8-bit integer—to reduce memory usage and speed up inference. QLoRA techniques combine quantization with LoRA. Direct Preference Optimization (DPO): Chat models typically use reinforcement learning from human feedback (RLHF) to align model outputs to human preferences. Though powerful, RLHF is complex and unstable. DPO promises similar benefits while being computationally lightweight and substantially simpler. Alongside parallel advances in open source models in the 3–70 billion parameter space, these evolving techniques could shift the dynamics of the AI landscape by providing smaller players, like startups and amateurs, with sophisticated AI capabilities that were previously out of reach. Customized local models and data pipelines Enterprises in 2024 can thus pursue differentiation through bespoke model development, rather than building wrappers around repackaged services from “Big AI.” With the right data and development framework , existing open source AI models and tools can be tailored to almost any real-world scenario, from customer support uses to supply chain management to complex document analysis. Open source models afford organizations the opportunity to develop powerful custom AI models—trained on their proprietary data and fine-tuned for their specific needs—quickly, without prohibitively expensive infrastructure investments. This is especially relevant in domains like legal, healthcare or finance, where highly specialized vocabulary and concepts may not have been learned by foundation models in pre-training. Legal, finance and healthcare are also prime examples of industries that can benefit from models small enough to be run locally on modest hardware. Keeping AI training, inference and retrieval augmented generation (RAG) local avoids the risk of proprietary data or sensitive personal information being used to train closed-source models or otherwise pass through the hands of third parties. And using RAG to access relevant information rather than storing all knowledge directly within the LLM itself helps reduce model size, further increasing speed and reducing costs. As 2024 continues to level the model playing field, competitive advantage will increasingly be driven by proprietary data pipelines that enable industry-best fine-tuning. More powerful virtual agents With more sophisticated, efficient tools and a year’s worth of market feedback at their disposal, businesses are primed to expand the use cases for virtual agents beyond just straightforward customer experience chatbots . As AI systems speed up and incorporate new streams and formats of information, they expand the possibilities for not just communication and instruction following, but also task automation. “2023 was the year of being able to chat with an AI. Multiple companies launched something, but the interaction was always you type something in and it types something back,” says Stanford’s Norvig. “In 2024, we’ll see the ability for agents to get stuff done for you . Make reservations, plan a trip, connect to other services.” Multimodal AI, in particular, significantly increases opportunities for seamless interaction with virtual agents. For example, rather than simply asking a bot for recipes, a user can point a camera at an open fridge and request recipes that can be made with available ingredients. Be My Eyes, a mobile app that connects blind and low vision individuals with volunteers to help with quick tasks, is piloting AI tools that help users directly interact with their surroundings through multimodal AI in lieu of awaiting a human volunteer. Explore IBM watsonx™ Assistant: market-leading conversational AI with seamless integration for the tools that power your business → Regulation, copyright and ethical AI concerns Elevated multimodal capabilities and lowered barriers to entry also open up new doors for abuse: deepfakes, privacy issues, perpetuation of bias and even evasion of CAPTCHA safeguards may become increasingly easy for bad actors. In January of 2024, a wave of explicit celebrity deepfakes hit social media; research from May 2023 indicated that there had been 8 times as many voice deepfakes posted online compared to the same period in 2022. [6] Ambiguity in the regulatory environment may slow adoption, or at least more aggressive implementation, in the short to medium term. There is inherent risk to any major, irreversible investment in an emerging technology or practice that might require significant retooling—or even become illegal—following new legislation or changing political headwinds in the coming years. In December 2023, the European Union (EU) reached provisional agreement on the Artificial Intelligence Act . Among other measures, it prohibits indiscriminate scraping of images to create facial recognition databases, biometric categorization systems with potential for discriminatory bias, “social scoring” systems and the use of AI for social or economic manipulation. It also seeks to define a category of “high-risk” AI systems, with potential to threaten safety, fundamental rights or rule of law, that will be subject to additional oversight. Likewise, it sets transparency requirements for what it calls “general-purpose AI (GPAI)” systems—foundation models—including technical documentation and systemic adversarial testing. But while some key players, like Mistral, reside in the EU, the majority of groundbreaking AI development is happening in America, where substantive legislation of AI in the private sector will require action from Congress—which may be unlikely in an election year. On October 30, the Biden administration issued a comprehensive executive order detailing 150 requirements for use of AI technologies by federal agencies; months prior, the administration secured voluntary commitments from prominent AI developers to adhere to certain guardrails for trust and security. Notably, both California and Colorado are actively pursuing their own legislation regarding individuals’ data privacy rights with regard to artificial intelligence. China has moved more proactively toward formal AI restrictions, banning price discrimination by recommendation algorithms on social media and mandating the clear labeling of AI-generated content. Prospective regulations on generative AI seek to require the training data used to train LLMs and the content subsequently generated by models must be “true and accurate,” which experts have taken to indicate measures to censor LLM output. Meanwhile, the role of copyrighted material in the training of AI models used for content generation, from language models to image generators and video models, remains a hotly contested issue. The outcome of the high-profile lawsuit filed by the New York Times against OpenAI may significantly affect the trajectory of AI legislation. Adversarial tools, like Glaze and Nightshade —both developed at the University of Chicago—have arisen in what may become an arms race of sorts between creators and model developers. Learn how IBM® watsonx.governance™ accelerates responsible, transparent and explainable AI workflows → Shadow AI (and corporate AI policies) For businesses, this escalating potential for legal, regulatory, economic or reputational consequences is compounded by how popular and accessible generative AI tools have become. Organizations must not only have a careful, coherent and clearly articulated corporate policy around generative AI, but also be wary of shadow AI: the “unofficial” personal use of AI in the workplace by employees. Also dubbed “shadow IT” or “BYOAI,” shadow AI arises when impatient employees seeking quick solutions (or simply wanting to explore new tech faster than a cautious company policy allows) implement generative AI in the workplace without going through IT for approval or oversight. Many consumer-facing services, some free of charge, allow even nontechnical individuals to improvise the use of generative AI tools. In one study from Ernst & Young, 90% of respondents said they use AI at work. [7] That enterprising spirit can be great, in a vacuum—but eager employees may lack relevant information or perspective regarding security, privacy or compliance. This can expose businesses to a great deal of risk. For example, an employee might unknowingly feed trade secrets to a public-facing AI model that continually trains on user input, or use copyright-protected material to train a proprietary model for content generation and expose their company to legal action. Like many ongoing developments, this underscores how the dangers of generative AI rise almost linearly with its capabilities. With great power comes great responsibility. Moving forward As we proceed through a pivotal year in artificial intelligence, understanding and adapting to emerging trends is essential to maximizing potential, minimizing risk and responsibly scaling generative AI adoption. Put generative AI to work with watsonx™ Learn how IBM can empower you to stay ahead of AI trends 1 “Gartner Places Generative AI on the Peak of Inflated Expectations on the 2023 Hype Cycle for Emerging Technologies,” Gartner, 16 August 2023 2 ”Deloitte’s State of Generative AI in the Enteprrise Quarter one report,” Deloitte, January 2024 3 ”What to Expect in AI in 2024,” Stanford University, 8 December 2023 4 ”Q&A: UW researcher discusses just how much energy ChatGPT uses,” University of Washington, 27 July 2023 5 “Generative AI in the Enterprise,” O’Reilly, 28 November 2023 6 ”Deepfaking it: America’s 2024 election coincides with AI boom,” Reuters, 30 May 2023 7 ”How organizations can stop skyrocketing AI use from fueling anxiety,” Ernst & Young, December 2023 Was this article helpful? Yes No Tags artificial intelligence Dave Bergmann Writer, Data & AI Trending Artificial intelligence July 15, 2024 Are bigger language models always better? 4 min read - As enterprises look to separate the hype from where AI can add true value, it’s unclear if increasingly larger language models will always lead to better business solutions. Sustainability July 11, 2024 10 ways artificial intelligence is transforming operations management 5 min read - Activities such as planning, organizing, inventory and supply chain management are ripe for improvement through artificial intelligence. Sustainability July 11, 2024 Accelerating the renewable energy transition 4 min read - Exploring the renewable energy sources available to companies and the steps they can take to accelerate their own clean energy transitions. More from Artificial intelligence July 17, 2024 ServiceNow and IBM revolutionize talent development with AI 4 min read - Generative AI is fundamentally changing the world of work by redefining the skills and jobs needed for the future. In fact, recent research from ServiceNow and Pearson found that an additional 1.76 million tech workers will be needed by 2028 in the US alone.  However, according to the IBM Institute for Business Value, less than half of CEOs surveyed (44%) have assessed the potential impact of generative AI on their workforces. To help customers develop and upskill their workforces to meet… July 16, 2024 Responsible AI is a competitive advantage 3 min read - In the era of generative AI, the promise of the technology grows daily as organizations unlock its new possibilities. However, the true measure of AI’s advancement goes beyond its technical capabilities. It’s about how technology is harnessed to reflect collective values and create a world where innovation benefits everyone, not just a privileged few. Prioritizing trust and safety while scaling artificial intelligence (AI) with governance is paramount to realizing the full benefits of this technology. It is becoming clear that… July 15, 2024 Taming the Wild West of AI-generated search results 4 min read - Companies are racing to integrate generative AI into their search engines, hoping to revolutionize the way users access information. However, this uncharted territory comes with a significant challenge: ensuring the accuracy and reliability of AI-generated search results. As AI models grapple with \"hallucinations\"—producing content that fills in gaps with inaccurate information—the industry faces a critical question: How can we harness the potential of AI while minimizing the spread of misinformation? Google's new generative AI search tool recently surprised users by… IBM Newsletters Get our newsletters and topic updates that deliver the latest thought leadership and insights on emerging trends. Subscribe now More newsletters\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_tool` with `{'query': 'LLMs for education'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['https://publish.illinois.edu/teaching-learninghub-byjen/benefits-of-llms-in-education/', 'https://www.packtpub.com/article-hub/large-language-models-llms-in-education', 'https://arxiv.org/html/2403.18105v1', 'https://www.merlyn.org/blog/first-ever-education-specific-language-models-open-door-to-trustworthy-generative-ai-for-teachers-and-students', 'https://www.linkedin.com/pulse/future-education-llms-personalized-learning-gavin-o-leary-p90ve', 'https://arxiv.org/abs/2403.18105', 'https://www.carnegielearning.com/blog/making-the-most-of-chatgpt/', 'https://www.nature.com/articles/d41586-023-03507-3', 'https://springsapps.com/knowledge/how-llm-can-transform-education', 'https://elearningindustry.com/exploring-the-role-of-large-language-models-in-education']\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `scrape_text` with `{'url': 'https://publish.illinois.edu/teaching-learninghub-byjen/benefits-of-llms-in-education/'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mBenefits of LLMs in Education – Jen's Teaching and Learning Hub Jen's Teaching and Learning Hub Home ChatGPT & Other LLMs What are LLMs? Risk of LLMs in Education Benefits of LLMs in Education GenAI as an Educational Tool Planning for AI in Education Additional LLM & AI Resources Canvas Tips Blog Benefits of LLMs in Education Introduction Large language models (LLMs) have the potential to greatly benefit education by assisting students and teachers by preparing students for a new kind of work, personalizing education, reducing time-consuming tasks, improving accessibility and inclusivity, and providing multilingual support. Script generated by ChatGPT Learn more: What are LLMs? Risks of LLMs in Education LLMs as an Educational Tool Planning for AI in Education Additional LLM & AI Resources Building Technological Skills From the beginning, LLMs have raised questions about the future of work in a variety of industries, from business to healthcare. What will future work look like? Will artificial intelligence be a required tool? By using LLMs in the classroom, students can begin to learn how to use them effectively and appropriately to prepare them for future careers that we may not even fathom today. This also builds their technological, reasoning, and critical thinking skills. Because LLMs require the correct prompt to get the desired response, students have to learn how to ask the right questions. Through trial and error, students learn to use the technology effectively and build critical thinking skills. Personalizing Education Teachers can create personalized lesson plans and customized projects for each student in a matter of minutes. Students can use a chatbot to get immediate feedback on their work by prompting it to review a text and make suggestions for improvements. Javaid et. al researched the potential opportunities of ChatGPT in the education system and found “the ChatGPT model has the potential to be used as a tool for developing summaries, flashcards, or quizzes based on a particular topic or subject area. By providing individualized, flexible, and exciting learning opportunities, ChatGPT has the potential to enhance student’s educational experiences.” By using LLMs to tailor the learning experience, teachers can “promote autonomy, competence, and relatedness, significantly enhancing student support and building a more effective learning environment (Alqahtani et. al., 2023).” In fact, Sal Khan with Khan Academy is already testing out this new potential with the brand-new Khanmigo (external link) . Personalized education can improve accessibility and inclusivity for all students, improving student support services and early interventions for at-risk students. See how ChatGPT can improve student accessibility and inclusivity through a chat with ChatGPT-3.5 (external link). Overall, I think Alqahtani et. al. says it best: “Ultimately, AI has the potential to transform how educators deliver personalized learning and support, improving outcomes for all students (2023).” Of course, with all things, only time will tell. Reducing Time-Consuming Tasks Teachers can utilize LLMs to cut down time on the more menial tasks of education, like writing quizzes, activities, and rubrics. These technologies can also build lesson plans, including creating a course description, learning objectives, and assessments (Alqahtani et. al., 2023). Javaid et. al states, “ChatGPT replies are quick, free, and often a wonderful place to start (2023).” LLMs can also grade and write personalized feedback.  Alqahtani et. al. (2023) identified the following benefits of using these systems for grading: Saves educators time and effort AI grading can be more consistent and systematic while reducing subjectivity and bias Allows educators to provide more timely feedback and focus more time on other important tasks Multilingual Support LLMs can translate across languages, including both spoken languages and computer science skills like coding. There are several uses of LLMs in language: Translation : LLMs can translate material. This might be helpful for students learning a new language or for English language learners (ELL). Students can practice second-language conversations with chatbots. ELL students can utilize chatbots to check their work or translate material into English or another language. Teachers can also use this technology to translate course content for ELL students. Grammar : LLMs can assist learners in improving their grammar in a new language and developing fundamental writing skills (Javaid et. al., 2023) Computer language : LLMs can be used to learn code, from writing to analyzing to finding mistakes. As technological advancement continues, computer and coding skills will be essential for students (Alqahtani et. al., 2023). Citations Alqahtani, T., Badreldin, H. A., Alrashed, M., Alshaya, A. I., Alghamdi, S. S., bin Saleh, K., Alowais, S. A., Alshaya, O. A., Rahman, I., Al Yami, M. S., & Albekairy, A. M. (2023). The emergent role of Artificial Intelligence, natural learning processing, and large language models in higher education and research. Research in Social and Administrative Pharmacy . https://doi.org/10.1016/j.sapharm.2023.05.016 Javaid, M., Haleem, A., Singh, R. P., Khan, S., & Khan, I. H. (2023). Unlocking the opportunities through CHATGPT tool towards ameliorating the education system. BenchCouncil Transactions on Benchmarks, Standards and Evaluations , (2), 100115. https://doi.org/10.1016/j.tbench.2023.100115 Jen's Teaching and Learning Hub Email: boberg2@illinois.edu Go to top\u001b[0m\u001b[32;1m\u001b[1;3m# Current Trends in AI: A Focus on Large Language Models (LLMs) for Education\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial Intelligence (AI) has been a transformative force across various sectors, and its influence continues to grow. This report will focus on the current trends in AI, with a particular emphasis on Large Language Models (LLMs) for education. The information presented is based on a comprehensive review of various sources, including articles from IBM, the University of Illinois, and other reputable sources.\n",
      "\n",
      "## Current Trends in AI\n",
      "\n",
      "AI has been evolving rapidly, with generative AI gaining significant attention in recent years. Generative AI refers to AI models that can generate new content, such as text, images, or music, based on the data they have been trained on. Large Language Models (LLMs) are a type of generative AI that can generate human-like text, making them particularly useful in various applications, including education.\n",
      "\n",
      "According to IBM, 2024 is a pivotal year for AI, with generative AI becoming more integrated into our everyday lives. The evolution of generative AI has mirrored that of computers, albeit on a dramatically accelerated timeline. Generative AI has already reached its “h\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Current Trends in AI: A Focus on Large Language Models (LLMs) for Education\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial Intelligence (AI) has been a transformative force across various sectors, and its influence continues to grow. This report will focus on the current trends in AI, with a particular emphasis on Large Language Models (LLMs) for education. The information presented is based on a comprehensive review of various sources, including articles from IBM, the University of Illinois, and other reputable sources.\n",
       "\n",
       "## Current Trends in AI\n",
       "\n",
       "AI has been evolving rapidly, with generative AI gaining significant attention in recent years. Generative AI refers to AI models that can generate new content, such as text, images, or music, based on the data they have been trained on. Large Language Models (LLMs) are a type of generative AI that can generate human-like text, making them particularly useful in various applications, including education.\n",
       "\n",
       "According to IBM, 2024 is a pivotal year for AI, with generative AI becoming more integrated into our everyday lives. The evolution of generative AI has mirrored that of computers, albeit on a dramatically accelerated timeline. Generative AI has already reached its “h"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "output_report = agent_executor.invoke({\"input\": \"Write a quick report on the current trends in AI. Focus on LLMs for education.\", \"chat_history\": []})\n",
    "\n",
    "Markdown(output_report[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
