<!DOCTYPE html>
<html>
  <head>
    <title>Presentation</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
        title: Introduction to LangGraph
        author: Your Name
        theme: white
        highlightStyle: monokai
        ---

        # Introduction to LangGraph

        ## Overview
        - **LangGraph**: A library for building stateful, multi-actor applications with LLMs.
        - **Core Benefits**:
        - Cycles
        - Controllability
        - Persistence

        ---

        ## Key Features
        - **Cycles and Branching**: Implement loops and conditionals in your apps.
        - **Persistence**: Automatically save state after each step in the graph.
        - **Human-in-the-Loop**: Interrupt graph execution to approve or edit next action.
        - **Streaming Support**: Stream outputs as they are produced by each node.
        - **Integration with LangChain**: Seamless integration but not required.

        ---

        ## Installation
        ```bash
        pip install -U langgraph
        pip install langchain-anthropic
        export ANTHROPIC_API_KEY=sk-...
        export LANGSMITH_TRACING=true
        export LANGSMITH_API_KEY=lsv2_sk_...
        ```

        ---

        ## Example Overview
        - **State**: Central concept in LangGraph.
        - **Execution**: Each node updates internal state with its return value.

        ---

        # Step-by-Step Tutorial

        ## Step 1: Initialize the Model and Tools
        - **LLM**: Use ChatAnthropic.
        - **Tools**: Define tools for the agent to use.

        ```python
        from langchain_anthropic import ChatAnthropic
        from langgraph.prebuilt import ToolNode
        from langchain_core.tools import tool

        @tool
        def search(query: str):
            if "sf" in query.lower():
                return ["It's 60 degrees and foggy."]
            return ["It's 90 degrees and sunny."]

        tools = [search]
        model = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0).bind_tools(tools)
        tool_node = ToolNode(tools)
        ```

        ---

        ## Step 2: Initialize Graph with State
        - **StateGraph**: Initialize by passing state schema.

        ```python
        from langgraph.graph import StateGraph, MessagesState

        workflow = StateGraph(MessagesState)
        ```

        ---

        ## Step 3: Define Graph Nodes
        - **Agent Node**: Decides actions to take.
        - **Tools Node**: Executes actions.

        ```python
        from langgraph.checkpoint import MemorySaver

        def call_model(state: MessagesState):
            response = model.invoke(state['messages'])
            return {"messages": [response]}

        workflow.add_node("agent", call_model)
        workflow.add_node("tools", tool_node)
        workflow.set_entry_point("agent")
        ```

        ---

        ## Step 4: Define Graph Edges
        - **Conditional Edge**: Depends on state contents.

        ```python
        def should_continue(state: MessagesState):
            if state['messages'][-1].tool_calls:
                return "tools"
            return END

        workflow.add_conditional_edges("agent", should_continue)
        workflow.add_edge("tools", 'agent')
        ```

        ---

        ## Step 5: Compile the Graph
        - **Compile**: Turn into a LangChain Runnable.

        ```python
        checkpointer = MemorySaver()
        app = workflow.compile(checkpointer=checkpointer)
        ```

        ---

        ## Step 6: Execute the Graph
        - **Invoke**: Run the compiled graph.

        ```python
        from langchain_core.messages import HumanMessage

        final_state = app.invoke(
            {"messages": [HumanMessage(content="what is the weather in sf")]},
            config={"configurable": {"thread_id": 42}}
        )
        print(final_state["messages"][-1].content)
        ```

        ---

        ## Example Execution
        ### San Francisco Weather
        - **Input**: "what is the weather in sf"
        - **Output**: "Temperature: 60 degrees Fahrenheit, Conditions: Foggy"

        ```python
        final_state = app.invoke(
            {"messages": [HumanMessage(content="what is the weather in San Francisco?")]},
            config={"configurable": {"thread_id": 42}}
        )
        print(final_state["messages"][-1].content)
        ```
    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>