{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2025-01-27-20-25-50.png\" width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{}', response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T20:28:31.077807Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 774494875, 'load_duration': 571586084, 'prompt_eval_count': 26, 'prompt_eval_duration': 169000000, 'eval_count': 2, 'eval_duration': 32000000}, id='run-85681c45-fbfd-4195-9260-a99df6941f38-0', usage_metadata={'input_tokens': 26, 'output_tokens': 2, 'total_tokens': 28})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm_structured_output = ChatOllama(model=\"llama3.2\", format=\"json\", temperature=0)\n",
    "\n",
    "llm_structured_output.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folder path was created at: lucas-test-agents'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_dir(folder_path):\n",
    "    \"\"\"\n",
    "    Creates a directory given a folder path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    \n",
    "    return f\"Folder path was created at: {folder_path}\"\n",
    "\n",
    "\n",
    "create_dir(\"lucas-test-agents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mWebRover/\u001b[m\u001b[m          \u001b[1m\u001b[36mlucas-test-agents/\u001b[m\u001b[m \u001b[1m\u001b[36mreact-voice-agent/\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A file was created at: ./lucas-test-agents/file-text.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_file(file_path, contents=\"\"):\n",
    "    \"\"\"\n",
    "    Creates a file with content.\n",
    "    If no content is provided it will create an empty file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(contents)\n",
    "    \n",
    "    return f\"A file was created at: {file_path}\"\n",
    "\n",
    "create_file(\"./lucas-test-agents/file-text.txt\", \"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads from file given its path.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    \n",
    "    return contents\n",
    "\n",
    "read_file(\"./lucas-test-agents/file-text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [create_dir, create_file, read_file]\n",
    "\n",
    "llm_tools = llm_structured_output.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt = f\"\"\"You are an agent that helps users with desktop tasks like reading and writing files and creating directories. You either call a tool\n",
    "from the options available: create_dir, create_file or read_file, or you return a summary of the tasks performed and at the end a string: END.\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "llm_agent = prompt_template | llm_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T21:30:19.116521Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'create_file', 'arguments': {'contents': '', 'file_path': 'lucas-locas-pancakes.md'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 438141625, 'load_duration': 26659959, 'prompt_eval_count': 330, 'prompt_eval_duration': 130000000, 'eval_count': 30, 'eval_duration': 279000000}, id='run-2a61ea11-f765-4ea6-842e-182bc2edb27a-0', tool_calls=[{'name': 'create_file', 'args': {'contents': '', 'file_path': 'lucas-locas-pancakes.md'}, 'id': '8d96d871-6bc1-465b-9165-38233700957e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 330, 'output_tokens': 30, 'total_tokens': 360})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent.invoke(\"Create file named lucas-locas-pancakes.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'create_file',\n",
       "  'args': {'contents': '', 'file_path': './test-agent.txt'},\n",
       "  'id': 'ae06a878-1490-4aaa-a766-9488c5521aed',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tool_call = llm_agent.invoke(\"Create a file named ./test-agent.txt\")\n",
    "output_tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    \"create_file\": create_file,\n",
    "    \"create_dir\": create_dir,\n",
    "    \"read_file\": read_file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(query, observations=[], actions_taken=[]):\n",
    "    \"\"\"\n",
    "    Calls the llm, it can return a tool call with arguments for calling different tools,\n",
    "    or an output to the user.\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "    Imagine you are a simple assistant tasked with managing a file system. You have access to three tools:\n",
    "    \n",
    "    1. create_dir: Creates a new directory.\n",
    "    2. create_file: Creates a new file and optionally writes content to it.\n",
    "    3. read_file: Reads the contents of an existing file.\n",
    "\n",
    "    Based on the user input and your observations, choose an action to execute. Your action must follow these guidelines:\n",
    "    \n",
    "    * Action Guidelines *\n",
    "    1) Only one action is allowed per iteration.\n",
    "    2) Be concise and specific about what to create, write, or read.\n",
    "    3) Provide clear reasoning for your action.\n",
    "    4) Always consider the current context before taking action.\n",
    "    \n",
    "    Respond in the following format:\n",
    "    Thought: {{Your reasoning here}}\n",
    "    Action: {{Action name with parameters}}\n",
    "    \n",
    "    Available Actions:\n",
    "    - create_dir [directory_name]\n",
    "    - create_file [file_name]; [content (optional)]\n",
    "    - read_file [file_name]\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the input for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    {template}\n",
    "\n",
    "    User Query: {query}\n",
    "    Observations: {observations}\n",
    "    Actions Taken So Far: {actions_taken}\n",
    "    \"\"\"\n",
    "\n",
    "    output = llm_agent.invoke(prompt)\n",
    "\n",
    "    if output.tool_calls:\n",
    "        for tool_call in output.tool_calls:\n",
    "            function_name = tool_call[\"name\"]\n",
    "            function_args = tool_call.get(\"args\", [])  # default to empty list if \"args\" is missing\n",
    "\n",
    "            # Check if function_name exists in tool_mapping\n",
    "            if function_name not in tool_mapping:\n",
    "                print(f\"Error: Unknown function name '{function_name}'\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Attempt to call the function with the provided arguments\n",
    "                tool_output = tool_mapping[function_name](**function_args)\n",
    "                actions_taken.append(function_name)\n",
    "                observations.append(tool_output)\n",
    "            except TypeError as e:\n",
    "                # Handle errors if the number of arguments does not match the expected number for the function\n",
    "                print(f\"Error: Invalid arguments for function '{function_name}': {e}\")\n",
    "    \n",
    "    \n",
    "    return output, actions_taken, observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T22:21:11.784171Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'create_dir', 'arguments': {'folder_path': 'lucas-tests-tool-calling'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 1901656625, 'load_duration': 568133000, 'prompt_eval_count': 558, 'prompt_eval_duration': 451000000, 'eval_count': 55, 'eval_duration': 553000000}, id='run-204906b5-3c97-4285-8b54-4c376a042e9e-0', tool_calls=[{'name': 'create_dir', 'args': {'folder_path': 'lucas-tests-tool-calling'}, 'id': 'bf8293d0-58b8-4be5-b3b6-24738374640e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 558, 'output_tokens': 55, 'total_tokens': 613}),\n",
       " ['create_dir'],\n",
       " ['Folder path was created at: lucas-tests-tool-calling'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_call(\"Create a folder named: lucas-tests-tool-calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': ('observation',\n",
       "  ['A file was created at: ./lucas-tests-tool-calling/test1.txt'])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_call(\"Create a file at: ./lucas-tests-tool-calling/test1.txt with the contents: Hello Lucas! You just made a tool call!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': ('observation', ['Hello Lucas! You just made a tool call!'])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_call(\"Read the file contents from  ./lucas-tests-tool-calling/test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T22:21:26.57492Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'create_dir', 'arguments': {'folder_path': './testing-multiple-calls'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 566164709, 'load_duration': 32140750, 'prompt_eval_count': 572, 'prompt_eval_duration': 136000000, 'eval_count': 30, 'eval_duration': 396000000} id='run-b03dcbe3-504f-4a74-896a-9f11ba4fadb4-0' tool_calls=[{'name': 'create_dir', 'args': {'folder_path': './testing-multiple-calls'}, 'id': '8f81c62c-0e25-4a4c-a377-e6732748866c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 572, 'output_tokens': 30, 'total_tokens': 602}\n",
      "content='' response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T22:21:27.36701Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'create_dir', 'arguments': {'folder_path': './testing-multiple-calls'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 789315125, 'load_duration': 9906458, 'prompt_eval_count': 588, 'prompt_eval_duration': 43000000, 'eval_count': 74, 'eval_duration': 735000000} id='run-a4970a0d-673a-45c2-889a-e4c2fbfcdcdd-0' tool_calls=[{'name': 'create_dir', 'args': {'folder_path': './testing-multiple-calls'}, 'id': '002309e1-7422-44e6-ae68-4b1a330d03f8', 'type': 'tool_call'}] usage_metadata={'input_tokens': 588, 'output_tokens': 74, 'total_tokens': 662}\n",
      "content='' response_metadata={'model': 'llama3.2', 'created_at': '2025-01-27T22:21:27.766626Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'create_file', 'arguments': {'contents': '', 'file_path': './testing-multiple-calls/nested-file.txt'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 396480959, 'load_duration': 10226959, 'prompt_eval_count': 606, 'prompt_eval_duration': 55000000, 'eval_count': 33, 'eval_duration': 329000000} id='run-e20f40b6-00af-4365-8f91-8d24a1030b59-0' tool_calls=[{'name': 'create_file', 'args': {'contents': '', 'file_path': './testing-multiple-calls/nested-file.txt'}, 'id': '9347418f-fc48-404d-9c64-b5faa350d463', 'type': 'tool_call'}] usage_metadata={'input_tokens': 606, 'output_tokens': 33, 'total_tokens': 639}\n",
      "Breaking after 3 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agent_loop(query):\n",
    "    iter_count = 0\n",
    "    obs = []\n",
    "    acts_taken = []\n",
    "    while True:\n",
    "        output,obs,acts_taken = llm_call(query, obs, acts_taken)\n",
    "        print(output)\n",
    "        iter_count+=1\n",
    "        if iter_count>=3:\n",
    "            print(f\"Breaking after {iter_count} iterations\")\n",
    "            break\n",
    "        if output.content!=\"\":\n",
    "            break\n",
    "    \n",
    "    return output.content\n",
    "\n",
    "\n",
    "agent_loop(\"Create a folder in current directory named 'testing-multiple-calls' and inside that folder create a file named nested-file.txt\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining:\n",
    "- [ ] Integrate a system message so the LLM knows when to stop solving the problem\n",
    "- [ ] Fix the prompt template stuff from the beggining\n",
    "- [ ] Fix the redundant looping issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
