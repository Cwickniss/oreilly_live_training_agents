{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example was taken from the langchain docs:\n",
    "# https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "# %pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./assets-resources/tree-of-thoughts.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of Thoughts: Deliberate Problem Solving\n",
      "with Large Language Models\n",
      "Shunyu Yao\n",
      "Princeton UniversityDian Yu\n",
      "Google DeepMindJeffrey Zhao\n",
      "Google DeepMindIzhak Shafran\n",
      "Google DeepMind\n",
      "Thomas L. Grifﬁths\n",
      "Princeton UniversityYuan Cao\n",
      "Google DeepMindKarthik Narasimhan\n",
      "Princeton University\n",
      "Abstract\n",
      "Language models are increasingly being deployed for general problem solving\n",
      "across a wide range of tasks\n",
      "GĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "jũƜŔũƜʱÊʲˤGjʱæʲˤ\u001dĵÉGĮŔũƜ\n",
      "ˤjũƜŔũƜʱçʲˤ\u001dĵÉˁ\u001dʟʟʟʟaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\n",
      "ˤjũƜŔũƜʱíʲˤÉĵÉˤʱĵũŗŝʲʟʟʟʟʟʟˤˤʝˤƛĎĵũĈĎƜ)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f0DUN\u0003GLIIHUHQFH\u0003E\\\u0003FRORU\n",
      "GĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "jũƜŔũƜGĮŔũƜ\n",
      "ˤjũƜŔũƜʱçʲˤòĦƙˤ\u001dĵĮŝƓŝŤòĮçƆˤƀƓƜĎˤ\u001dĵÉˤʱ\u001dĵÉˁ\u001dʲaÊĠĵŗƓŤƆˤſĵŤòGĮŔũƜ\n",
      "ˤjũƜŔũƜʱíʲˤÉŗòòˤĵƙˤĎĵũĈĎŤŝˤʱÉĵÉʲʟʟʟʟʟʟʟʟʟʟˤˤƛĎĵũĈĎƜ\n",
      "ʱçʲˤ\u001dĎÊđĮˤĵƙˤĎĵũĈĎƜˤŗĵĭŔƜđĮĈˤʱ\u001dĵÉʲʱÊʲˤGĮŔũƜˁjũƜŔũƜˤŗĵĭŔƜđĮĈˤʱGjʲFigure 1: Schematic\n",
      "Chain-of-thought (CoT) prompting [35] was proposed to address cases where the mapping of\n",
      "inputxto outputyis non-trivial (e.g. when xis a math question and yis the ﬁnal numerical answer).\n",
      "The key idea is to introduce a chain of thoughtsz1,···,znto bridgexandy, where each ziis a\n",
      "coherent language sequence that serves as a meaningful intermediate step toward problem solving\n",
      "(e.g.zicould be an interme\n",
      "learned (e.g. AlphaGo [ 26]). We propose a third alternative, by using the LM to deliberately reason\n",
      "about states. When applicable, such a deliberate heuristic can be more ﬂexible than programmed\n",
      "rules, and more sample-efﬁcient than learned models. Similar to the thought generator, we consider\n",
      "two strategies to evaluate states either independently or together:\n",
      "(a)Value each state independently: V(\n",
      "Game of 24 Creative Writing 5x5 Crosswords\n",
      "Input 4 numbers (4 9 10 13) 4 random sentences 10 clues (h1. presented;..)\n",
      "Output An equation to reach 24\n",
      "(13-9)*(10-4)=24A passage of 4 paragraphs\n",
      "ending in the 4 sentences5x5 letters: SHOWN;\n",
      "WIRRA; A V AIL; ...\n",
      "Thoughts 3 intermediate equations\n",
      "(13-9=4 (left 4,4,10); 10-\n",
      "4=6 (left 4,6); 4*6=24)A short writing plan\n",
      "(1. Introduce a book that\n",
      "connects...)W\n",
      "Method Success\n",
      "IO prompt 7.3%\n",
      "CoT prompt 4.0%\n",
      "CoT-SC (k=100) 9.0%\n",
      "ToT (ours) (b=1) 45%\n",
      "ToT (ours) (b=5) 74%\n",
      "IO + Reﬁne (k=10) 27%\n",
      "IO(best of 100) 33%\n",
      "CoT (best of 100) 49%\n",
      "Table 2: Game of 24 Results.\n",
      "0 25 50 75 1000.20.40.6(a) Success rate with nodes visited\n",
      "IO (best of k)\n",
      "CoT (best of k)\n",
      "ToT (b=1...5)\n",
      "1 2 3 4Correct0.00.20.40.6(b) Samples failed at each step\n",
      "CoT\n",
      "ToT (b=5) Figure 3: Game of 24 (a\n",
      "µŗƓŤòˤÊˤçĵĎòŗòĮƜˤŔÊŝŝÊĈòˤĵƙˤʁˤŝĎĵŗƜˤŔÊŗÊĈŗÊŔĎŝʛˤĎòˤòĮíˤŝòĮŤòĮçòˤĵƙˤòÊçĎˤŔÊŗÊĈŗÊŔĎˤĭũŝƜˤæòʝˤɾʛˤGƜˤƓŝĮ˙ƛˤíđƙƙƓçũĦƜˤƘĵˤíĵˤÊˤĎÊĮíŝŤÊĮíˤđƙˤƆĵũˤĠũŝƜˤŝŤÊĮíˤĵĮˤƆĵũŗˤĎÊĮíŝʛˤɿʛˤGƜˤçÊũĈĎƜˤĎđĭˤĵƙƙˤĈũÊŗíˤƛĎÊƜˤŝŔÊçòˤŝĭòĦĦòíˤĵƙˤŝòÊŗòíˤŝŤòÊģʛˤʀʛˤµĎòĮˤŝĎòˤíƓíĮ˒ƛˤĦđģòˤÊˤĈũƆˤƀĎĵˤƀÊŝˤƛŗƆđĮĈˤƘĵˤŔƓçģˤĎòŗˤũŔʜˤŝĎòˤŝŤÊŗŤòíˤũŝđĮĈˤŝƓĈĮˤĦÊĮĈũÊĈòʛˤʁʛˤ)ÊçĎˤŔòŗŝĵĮˤƀĎĵˤģĮĵƀŝˤƆĵũˤĎÊŝˤÊˤíđƙćòŗòĮƜˤŔòŗçòŔƜƓĵĮˤĵƙˤƀĎĵˤƆĵũˤÊŗòʛˤˤɾʛˤGĮ\n",
      ">\u000b\n",
      "Y\u0016\u0011\u0003HORSH\n",
      "\u000f\u0003\u0016\u0011\u0015\f\u000f\u0003\u000b\n",
      "K\u0015\u0011\u0003YDOXH\n",
      "\u000f\u0003\u0015\u0011\u0013\f\u000f\u0003\u000b\n",
      "K\u0014\u0011\u0003SDUFK\n",
      "\u000f\u0003\u0014\u0011\u001c\f\u000f\u0003\u000b\n",
      "Y\u0018\u0011\u0003FRYHW\n",
      "\u000f\u0003\u0013\u0011\u0019\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0013\u0014\f\u000f\u0003\u000b\n",
      "K\u0015\u0011\u0003PHULW\n",
      "\u000f\u0003\u0013\u0011\u0017\f\u000f\u0003\u000b\n",
      "Y\u0014\u0011\u0003DOORZ\n",
      "\u000f\u0003\u0013\u0011\u0015\f\u000f\u0003\u000b\n",
      "Y\u0015\u0011\u0003JULQG\n",
      "\u000f\u0003\u0013\u0011\u0014\f\u000f\u0003\u000b\n",
      "K\u0017\u0011\u0003OHSHU\n",
      "\u000f\u0003\u0013\u0011\u0014\f@\n",
      "Y\u0016\u0011\u0003HORSH\n",
      "0XOWLSOH\u0003UXQV3DUVH\u000f\u0003ILOWHU\u0003RXW\u0003QRQ\u0010ILYH\u0010OHWWHU\u000f\u0003VFRUH\u000f\u0003DJJUHJDWH\n",
      "&KRRVH\u0003\u000bVRIW\u0003VHOI\u0010FRQVLVWHQF\\\"\f\u0014\u00110D[\u0015\u00110D[\u0003ZLWKRXW\u0003YLRODWH\u0016\u0011')6\n",
      "GĮŔũƜˤ\u001dĦũòŝĎɿʛĭĵŤĵŗĎɾʛƘÊŝģŝĎʁʛŝÊĦĵĮƘÊŝģŝƘÊŝģŝ\n",
      "ĎʁʛˤŝÊĦĵĮˤʱŝũŗòʲſʂʛˤŝŗíŗƆˤʱĦĵƀʲſʀʛˤŝƜŗđĮ\n",
      "Self-reﬂection. Using LLMs to assess the viability of their own predictions is becoming an in-\n",
      "creasingly important procedure in problem solving. [ 25,17,21] introduced the “self-reﬂection”\n",
      "mechanism, in which LMs provide feedback to their generation candidates. [ 4] improves LMs code\n",
      "generation accuracy by injecting feedback messages generated by the LM itself based on its code\n",
      "execution results.\n",
      "References\n",
      "[1]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\n",
      "G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural\n",
      "information processing systems , 33:1877–1901, 2020.\n",
      "[2]C. Browne, E. J. Powley, D. Whitehouse, S. M. M. Lucas, P. I. Cowling, P. Rohlfshagen,\n",
      "S. Tavener, D. P. Liebana, S. Samothrakis, and S. Colton. A su\n",
      "[20] OpenAI. Gpt-4 technical report. ArXiv , abs/2303.08774, 2023.\n",
      "[21] D. Paul, M. Ismayilzada, M. Peyrard, B. Borges, A. Bosselut, R. West, and B. Faltings. Reﬁner:\n",
      "Reasoning feedback on intermediate representations, 2023.\n",
      "[22] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Improving language understanding\n",
      "by generative pre-training. OpenAI blog , 2018.\n",
      "[23] A. Radford, J. Wu, R. C\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"tree_of_thoughts\",\n",
    "    \"Searches and returns excerpts from the tree of thoughts paper.\",\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an AI and do not experience physical fatigue like humans do. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 11, 'total_tokens': 32}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4c36f55b-a8a5-4c85-a480-edf8dde6b98e-0', usage_metadata={'input_tokens': 11, 'output_tokens': 21, 'total_tokens': 32})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "llm.invoke(\"Are you tired?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Tree of Thoughts technique is a framework for language model inference that allows models to perform deliberate decision-making by considering multiple reasoning paths and self-evaluating choices to decide the next course of action. It generalizes over the popular \"Chain of Thought\" approach and enables exploration over coherent units of text (\"thoughts\") that serve as intermediate steps toward problem-solving. This technique enhances language models\\' problem-solving abilities on tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role.\\n\\nThe Tree of Thoughts framework involves decomposing the intermediate process into thought steps, generating potential thoughts from each state, heuristically evaluating states, and using a search algorithm to explore multiple reasoning paths over thoughts. It addresses the shortcomings of existing approaches by exploring different continuations within a thought process locally and incorporating planning, lookahead, or backtracking globally to evaluate different options.\\n\\nThe framework allows for flexibility in thought decomposition, thought generation, state evaluation, and search algorithms. It can be applied to various tasks and problem-solving scenarios, making language models more autonomous and intelligent in decision-making and problem-solving processes.\\n\\nThe Tree of Thoughts technique has been shown to significantly enhance language models\\' problem-solving abilities on tasks such as the Game of 24, Creative Writing, and Mini Crosswords. It provides a way to translate classical insights about problem-solving into actionable methods for contemporary language models, improving their capabilities in solving complex problems that are not easily formalized.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"what is the tree of thoughts technique?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke(\n",
    "    {\"input\": \"How did they evaluated the performance of the technique?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The performance of the technique was evaluated using a framework called Tree of Thoughts (ToT). The ToT framework involves maintaining a tree of coherent language sequences that serve as intermediate steps toward problem-solving. The LM (Language Model) self-evaluates the progress of different intermediate thoughts through a deliberate reasoning process instantiated in language. This implementation of search heuristics via LM self-evaluation and deliberation is novel and allows for systematic exploration of the tree of thoughts with lookahead and backtracking.\\n\\nThe ToT framework was applied to three tasks: Game of 24, Creative Writing, and Crosswords. The tasks required deductive, mathematical, commonsense, and lexical reasoning abilities, as well as systematic planning or search. The ToT framework obtained superior results on all three tasks by being general and flexible enough to support different levels of thoughts, different ways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of different problems.\\n\\nThe performance of the ToT framework was compared with existing methods such as Input-Output (IO) prompting. The results showed that the ToT framework outperformed existing methods in terms of problem-solving capabilities and performance metrics.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"output\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
